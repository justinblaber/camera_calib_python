{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:44.817057Z",
     "start_time": "2020-05-26T17:03:44.815274Z"
    }
   },
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains general utilities used in different modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:45.160715Z",
     "start_time": "2020-05-26T17:03:44.819086Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:45.164404Z",
     "start_time": "2020-05-26T17:03:45.162267Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T12:57:53.520901Z",
     "start_time": "2020-05-18T12:57:53.517436Z"
    }
   },
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason I can't find a built-in that will reverse and return a list without doing some iterable thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:45.173123Z",
     "start_time": "2020-05-26T17:03:45.165634Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def reverse(l): return l[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General numpy/torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch2np` converts a torch tensor to numpy array since its easy to forget when you need to call `detach` and `cpu` and the order required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:45.179313Z",
     "start_time": "2020-05-26T17:03:45.175142Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def torch2np(A):\n",
    "    if not isinstance(A, tuple): # Recursion exit condition\n",
    "        if isinstance(A, torch.Tensor): return A.detach().cpu().numpy()\n",
    "        else:                           return A\n",
    "    return tuple(map(torch2np, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`assert_allclose` checks if two things, `A` and `B`, are close to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:45.185470Z",
     "start_time": "2020-05-26T17:03:45.180846Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def _assert_allclose(A, B, **kwargs):\n",
    "    if not isinstance(A, tuple): # Recursion exit condition\n",
    "        try:    assert(np.allclose(A, B, **kwargs))\n",
    "        except: assert(np.all(A == B))\n",
    "        return\n",
    "    \n",
    "    for a,b in zip(A,B): _assert_allclose(a, b, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:45.191684Z",
     "start_time": "2020-05-26T17:03:45.186755Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def assert_allclose(A, B, **kwargs):\n",
    "    A, B = map(torch2np, [A, B]) # Conversion needed if torch tensor is on gpu, otherwise np.allclose fails\n",
    "    _assert_allclose(A, B, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.266865Z",
     "start_time": "2020-05-26T17:03:45.192624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2820, 0.2418, 0.4961],\n",
       "         [0.2044, 0.9283, 0.6214],\n",
       "         [0.1171, 0.5539, 0.7734],\n",
       "         [0.2433, 0.7067, 0.6499]], device='cuda:0'),\n",
       " array([[-1.65585541, -0.40968438,  0.79874702],\n",
       "        [-1.31956664, -1.40018963, -0.30673471],\n",
       "        [ 0.39033917, -1.1941749 ,  0.24503917],\n",
       "        [-0.01609732,  0.83943242,  0.28223799]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand((4,3)).cuda(); \n",
    "B = np.random.normal(size=(4,3))\n",
    "A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.270587Z",
     "start_time": "2020-05-26T17:03:47.267862Z"
    }
   },
   "outputs": [],
   "source": [
    "assert_allclose(A, A+1e-5, atol=1e-5)\n",
    "assert_allclose((A, (B, 1., 'test')), (A+1e-5, (B+1e-5, 1.+1e-5, 'test')), atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have multiple functions that should work for torch and numpy, we should have a way to test for both without having to write duplicate tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.281159Z",
     "start_time": "2020-05-26T17:03:47.271510Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def assert_allclose_f(f, x, y, **kwargs):\n",
    "    if not isinstance(x, tuple): x = (x,)\n",
    "    assert_allclose(f(*x), y, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.287417Z",
     "start_time": "2020-05-26T17:03:47.282120Z"
    }
   },
   "outputs": [],
   "source": [
    "# export \n",
    "def assert_allclose_f_ttn(f, x, y, **kwargs): # ttn == \"torch, then numpy\"\n",
    "    assert_allclose_f(f, x, y, **kwargs) # Torch test\n",
    "    x, y = map(torch2np, [x,y])\n",
    "    assert_allclose_f(f, x, y, **kwargs) # Numpy test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General point stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`augment` will add ones to points; useful for affine and homography xforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.293634Z",
     "start_time": "2020-05-26T17:03:47.288499Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def augment(ps):\n",
    "    if isinstance(ps, np.ndarray): \n",
    "        return np.c_[ps, np.ones(len(ps), dtype=ps.dtype)]\n",
    "    else:                          \n",
    "        return torch.cat([ps, ps.new_ones((len(ps), 1))], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.301725Z",
     "start_time": "2020-05-26T17:03:47.295312Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = torch.tensor([[0.1940, 0.2536],\n",
    "                   [0.2172, 0.1626],\n",
    "                   [0.9834, 0.2700],\n",
    "                   [0.5324, 0.7137]]).cuda()\n",
    "assert_allclose_f_ttn(augment, ps, torch.tensor([[0.1940, 0.2536, 1.0000],\n",
    "                                                 [0.2172, 0.1626, 1.0000],\n",
    "                                                 [0.9834, 0.2700, 1.0000],\n",
    "                                                 [0.5324, 0.7137, 1.0000]]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.305347Z",
     "start_time": "2020-05-26T17:03:47.303004Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def deaugment(ps): return ps[:, 0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.312198Z",
     "start_time": "2020-05-26T17:03:47.306367Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = torch.tensor([[0.1940, 0.2536, 1.0000],\n",
    "                   [0.2172, 0.1626, 1.0000],\n",
    "                   [0.9834, 0.2700, 1.0000],\n",
    "                   [0.5324, 0.7137, 1.0000]]).cuda()\n",
    "assert_allclose_f_ttn(deaugment, ps, torch.tensor([[0.1940, 0.2536],\n",
    "                                                   [0.2172, 0.1626],\n",
    "                                                   [0.9834, 0.2700],\n",
    "                                                   [0.5324, 0.7137]]).cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`normalize` will divide by last column and remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.317376Z",
     "start_time": "2020-05-26T17:03:47.313082Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def normalize(ps): return deaugment(ps)/ps[:, [-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T02:00:08.716743Z",
     "start_time": "2020-05-26T02:00:08.710841Z"
    }
   },
   "source": [
    "`unitize` will make norm of each point 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.323681Z",
     "start_time": "2020-05-26T17:03:47.318345Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def unitize(ps): return ps/np.linalg.norm(ps, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T00:03:08.202947Z",
     "start_time": "2020-05-26T00:03:08.198828Z"
    }
   },
   "source": [
    "`ps_bb` is points bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.329595Z",
     "start_time": "2020-05-26T17:03:47.324664Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def ps_bb(ps): return np.stack([np.min(ps, axis=0), np.max(ps, axis=0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`array_bb` is array integer bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.335663Z",
     "start_time": "2020-05-26T17:03:47.330609Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def array_bb(arr): return np.array([[0,0], [arr.shape[1]-1, arr.shape[0]-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bb_grid` is integer bounding box grid; i,j is swapped to x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.344196Z",
     "start_time": "2020-05-26T17:03:47.336611Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def bb_grid(bb):\n",
    "    assert_allclose(bb.dtype, np.int)\n",
    "    return reverse(np.mgrid[bb[0,1]:bb[1,1]+1, bb[0,0]:bb[1,0]+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bb_array` applies integer bounding box to array and returns the sub array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.350161Z",
     "start_time": "2020-05-26T17:03:47.345172Z"
    }
   },
   "outputs": [],
   "source": [
    "# export \n",
    "def bb_array(arr, bb): \n",
    "    assert_allclose(bb.dtype, np.int)\n",
    "    return arr[bb[0,1]:bb[1,1]+1, bb[0,0]:bb[1,0]+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bb_sz` returns the size of an integer bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.355944Z",
     "start_time": "2020-05-26T17:03:47.351057Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def bb_sz(bb):\n",
    "    assert_allclose(bb.dtype, np.int)\n",
    "    return np.array([bb[1,1]-bb[0,1]+1, bb[1,0]-bb[0,0]+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grid2ps` converts grid to points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.361706Z",
     "start_time": "2020-05-26T17:03:47.357103Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def grid2ps(X, Y, order='C'): return np.c_[X.ravel(order), Y.ravel(order)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`array_ps` is array points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.367281Z",
     "start_time": "2020-05-26T17:03:47.362760Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def array_ps(arr): return grid2ps(*bb_grid(array_bb(arr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pmm` is point matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.373085Z",
     "start_time": "2020-05-26T17:03:47.368494Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def pmm(A, ps, aug=False): \n",
    "    single = len(ps.shape) == 1\n",
    "    if single: ps = ps[None]\n",
    "    if aug:    ps = augment(ps)\n",
    "    ps = (A@ps.T).T\n",
    "    if aug:    ps = normalize(ps) # works for both affine and homography transforms\n",
    "    if single: ps = ps[0]\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.380283Z",
     "start_time": "2020-05-26T17:03:47.374057Z"
    }
   },
   "outputs": [],
   "source": [
    "A = torch.tensor([[0.9571, 0.5551],\n",
    "                  [0.8914, 0.2626]]).cuda()\n",
    "ps = torch.tensor([[0.1940, 0.2536],\n",
    "                   [0.2172, 0.1626],\n",
    "                   [0.9834, 0.2700],\n",
    "                   [0.5324, 0.7137]]).cuda()\n",
    "assert_allclose_f_ttn(pmm, (A,ps), torch.tensor([[0.3265, 0.2395],\n",
    "                                                 [0.2981, 0.2363],\n",
    "                                                 [1.0911, 0.9475],\n",
    "                                                 [0.9057, 0.6620]]).cuda(), atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`condition_mat` is typically used to \"condition\" points to improve conditioning; its inverse is usually applied afterwards. It sets the mean of the points to zero and the average distance to `sqrt(2)`. I use the term \"condition\" here so it doesn't get confused with \"normalization\" which is used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.384501Z",
     "start_time": "2020-05-26T17:03:47.381286Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def condition_mat(ps):\n",
    "    xs, ys = ps[:, 0], ps[:, 1]\n",
    "    mean_x, mean_y = xs.mean(), ys.mean()\n",
    "    s_m = np.sqrt(2)*len(ps)/(np.sqrt((xs-mean_x)**2+(ys-mean_y)**2)).sum()\n",
    "    return np.array([[s_m,   0, -mean_x*s_m],\n",
    "                     [  0, s_m, -mean_y*s_m],\n",
    "                     [  0,   0,           1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.395992Z",
     "start_time": "2020-05-26T17:03:47.385473Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def condition(ps):\n",
    "    T = condition_mat(ps)\n",
    "    return pmm(T, ps, aug=True), T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.414282Z",
     "start_time": "2020-05-26T17:03:47.396933Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = array_ps(np.zeros((3,2)))\n",
    "assert_allclose(ps, np.array([[0, 0],\n",
    "                              [1, 0],\n",
    "                              [0, 1],\n",
    "                              [1, 1],\n",
    "                              [0, 2],\n",
    "                              [1, 2]]))\n",
    "assert_allclose(condition_mat(ps), np.array([[ 1.55063424,  0.        , -0.77531712],\n",
    "                                             [ 0.        ,  1.55063424, -1.55063424],\n",
    "                                             [ 0.        ,  0.        ,  1.        ]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`homography` estimates a homography between two sets of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.423167Z",
     "start_time": "2020-05-26T17:03:47.415237Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def homography(ps1, ps2):    \n",
    "    # Condition and augment points\n",
    "    (ps1_cond, T1), (ps2_cond, T2) = map(condition, [ps1, ps2])\n",
    "    ps1_cond, ps2_cond = map(augment, [ps1_cond, ps2_cond])\n",
    "    \n",
    "    # Form homogeneous system\n",
    "    L = np.r_[np.c_[ps1_cond, np.zeros_like(ps1_cond), -ps2_cond[:, 0:1]*ps1_cond],\n",
    "              np.c_[np.zeros_like(ps1_cond), ps1_cond, -ps2_cond[:, 1:2]*ps1_cond]]\n",
    "    \n",
    "    # Solution is the last row of V\n",
    "    _,_,V = np.linalg.svd(L)\n",
    "    H12_cond = V[-1, :].reshape(3,3)\n",
    "    \n",
    "    # Undo conditioning\n",
    "    H12 = np.linalg.inv(T2)@H12_cond@T1\n",
    "    H12 /= H12[2,2] # Sets H12[2,2] to 1\n",
    "    return H12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`approx_R` gives the nearest rotational approximation to the input matrix (I believe frobenium norm). Note that for a proper rotation determinant must be +1, which is checked after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.428790Z",
     "start_time": "2020-05-26T17:03:47.424347Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def approx_R(R):\n",
    "    [U,_,V] = np.linalg.svd(R)\n",
    "    R = U@V\n",
    "    if np.abs(np.linalg.det(R)-1) > np.finfo(np.float32).eps:\n",
    "        R = np.full((3,3), np.nan)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ellipse stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample_2pi` prevents accidentally resampling 2pi twice by linspacing with an additional sample and then removing the last sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.435003Z",
     "start_time": "2020-05-26T17:03:47.429731Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def sample_2pi(num_samples): return np.linspace(0, 2*np.pi, num_samples+1)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.441045Z",
     "start_time": "2020-05-26T17:03:47.436054Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def sample_ellipse(h, k, a, b, alpha, num_samples):\n",
    "    sin, cos = np.sin, np.cos    \n",
    "    \n",
    "    thetas = sample_2pi(num_samples)\n",
    "    return np.c_[a*cos(alpha)*cos(thetas) - b*sin(alpha)*sin(thetas) + h,\n",
    "                 a*sin(alpha)*cos(thetas) + b*cos(alpha)*sin(thetas) + k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.447115Z",
     "start_time": "2020-05-26T17:03:47.442076Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def ellipse2conic(h, k, a, b, alpha):\n",
    "    sin, cos = np.sin, np.cos\n",
    "    \n",
    "    A = a**2*sin(alpha)**2 + b**2*cos(alpha)**2\n",
    "    B = 2*(b**2 - a**2)*sin(alpha)*cos(alpha)\n",
    "    C = a**2*cos(alpha)**2 + b**2*sin(alpha)**2\n",
    "    D = -2*A*h - B*k\n",
    "    E = -B*h - 2*C*k\n",
    "    F = A*h**2 + B*h*k + C*k**2 - a**2*b**2\n",
    "\n",
    "    return np.array([[  A, B/2, D/2],\n",
    "                     [B/2,   C, E/2],\n",
    "                     [D/2, E/2,   F]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.456817Z",
     "start_time": "2020-05-26T17:03:47.448105Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def conic2ellipse(Aq):\n",
    "    sqrt, abs, arctan, pi = np.sqrt, np.abs, np.arctan, np.pi\n",
    "    eps = np.finfo(np.float32).eps # Use single precision for more wiggle room\n",
    "    \n",
    "    A = Aq[0, 0]\n",
    "    B = 2*Aq[0, 1]\n",
    "    C = Aq[1, 1]\n",
    "    D = 2*Aq[0, 2]\n",
    "    E = 2*Aq[1, 2]\n",
    "    F = Aq[2, 2]\n",
    "\n",
    "    # Return nans if input conic is not ellipse\n",
    "    if np.any(~np.isfinite(Aq.ravel())) or np.abs(B**2-4*A*C) < eps or B**2-4*A*C > 0:\n",
    "        return np.full(5, np.nan)\n",
    "\n",
    "    # Equations below are from https://math.stackexchange.com/a/820896/39581\n",
    "\n",
    "    # \"coefficient of normalizing factor\"\n",
    "    q = 64*(F*(4*A*C-B**2)-A*E**2+B*D*E-C*D**2)/(4*A*C-B**2)**2\n",
    "\n",
    "    # distance between center and focal point\n",
    "    s = 1/4*sqrt(abs(q)*sqrt(B**2+(A-C)**2))\n",
    "\n",
    "    # ellipse parameters\n",
    "    h = (B*E-2*C*D)/(4*A*C-B**2)\n",
    "    k = (B*D-2*A*E)/(4*A*C-B**2)\n",
    "    a = 1/8*sqrt(2*abs(q)*sqrt(B**2+(A-C)**2)-2*q*(A+C))\n",
    "    b = sqrt(a**2-s**2)\n",
    "    # Get alpha; note that range of alpha is [0, pi)\n",
    "    if abs(q*A-q*C) < eps and abs(q*B) < eps:         alpha = 0 # Circle\n",
    "    elif abs(q*A-q*C) < eps and q*B > 0:              alpha = 1/4*pi\n",
    "    elif abs(q*A-q*C) < eps and q*B < 0:              alpha = 3/4*pi\n",
    "    elif q*A-q*C > 0 and (abs(q*B) < eps or q*B > 0): alpha = 1/2*arctan(B/(A-C))\n",
    "    elif q*A-q*C > 0 and q*B < 0:                     alpha = 1/2*arctan(B/(A-C)) + pi\n",
    "    elif q*A-q*C < 0:                                 alpha = 1/2*arctan(B/(A-C)) + 1/2*pi\n",
    "    else: raise RuntimeError('\"Impossible\" condition reached; please debug')\n",
    "\n",
    "    return h, k, a, b, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T13:16:42.671125Z",
     "start_time": "2020-05-18T13:16:42.666722Z"
    }
   },
   "source": [
    "Let `grad_array` be a function, as I might want to change how gradients are computed; i,j is swapped to x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.468956Z",
     "start_time": "2020-05-26T17:03:47.458027Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def grad_array(arr): return reverse(np.gradient(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wlstsq` is weighted least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:47.483028Z",
     "start_time": "2020-05-26T17:03:47.472620Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def wlstsq(A, b, W=None):\n",
    "    # Weights should be a diagonal matrix with sqrt of the input weights\n",
    "    if W is not None:\n",
    "        W = np.sqrt(W.ravel())\n",
    "        A, b = A*W[:,None], b*W\n",
    "    return np.linalg.lstsq(A, b, rcond=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:36:21.604772Z",
     "start_time": "2020-05-03T20:36:21.600609Z"
    }
   },
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T17:03:48.149363Z",
     "start_time": "2020-05-26T17:03:47.484917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted cb_geom.ipynb.\n",
      "Converted control_refine.ipynb.\n",
      "Converted coordinate_graph.ipynb.\n",
      "Converted fiducial_detect.ipynb.\n",
      "Converted image.ipynb.\n",
      "Converted modules.ipynb.\n",
      "Converted test.ipynb.\n",
      "Converted utils.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
