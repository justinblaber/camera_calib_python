{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:45.703264Z",
     "start_time": "2020-07-19T20:48:45.700968Z"
    }
   },
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains general utilities used in different modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:46.872948Z",
     "start_time": "2020-07-19T20:48:45.708163Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "import hashlib\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import ipykernel\n",
    "import nbdev.export\n",
    "import numpy as np\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from IPython.display import Javascript, display\n",
    "from notebook.notebookapp import list_running_servers\n",
    "from PIL import Image\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:46.876444Z",
     "start_time": "2020-07-19T20:48:46.874288Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy/torch conversion stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general I'd like to have functions which work for both numpy and torch since the APIs aren't exactly the same. The approach I've taken is to write the function in `torch` (if possible) then add a function decorator `numpyify` to allow it to work with `numpy` arrays. This approach is far from perfect but it seems to have worked ok for most cases for me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`args_loop` assumes arguments are grouped in tuples or dictionaries, which is mostly true as `*args` and `**kwargs` are tuples and dictionaries, respectively. This will loop over and apply `callback` to each argument. Again, not perfect, but seems to work for most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:46.892617Z",
     "start_time": "2020-07-19T20:48:46.877916Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def args_loop(args, callback):\n",
    "    if isinstance(args, tuple):  return tuple([args_loop(arg, callback) for arg in args])\n",
    "    elif isinstance(args, dict): return {key: args_loop(arg, callback) for key,arg in args.items()}\n",
    "    else:                        return callback(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Converter` is a base class which will convert input arguments. It keeps track if any arguments were successfully converted which can be used to determine if outputs of the function should be converted back. Again, not perfect but it seems to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:46.907005Z",
     "start_time": "2020-07-19T20:48:46.896639Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class Converter():\n",
    "    def __init__(self): self.converted = False\n",
    "    \n",
    "    def predicate(self, arg): raise NotImplementedError('Please implement predicate')\n",
    "    def formatter(self, arg): raise NotImplementedError('Please implement formatter')\n",
    "        \n",
    "    def callback(self, arg):\n",
    "        if self.predicate(arg): \n",
    "            self.converted = True\n",
    "            return self.formatter(arg)\n",
    "        else:                   \n",
    "            return arg\n",
    "        \n",
    "    def __call__(self, args):\n",
    "        self.converted = False\n",
    "        return args_loop(args, self.callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch2np` will convert arguments from torch to numpy arrays. It should work for all cases (tensors which require gradients and cuda tensors) and will use the same underlying data and `dtype`.\n",
    "\n",
    "NOTE: The `converted` flag for `torch2np` will not be thread safe, calling `torch2np = Torch2np()` per invocation should make it safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:46.917385Z",
     "start_time": "2020-07-19T20:48:46.910457Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class Torch2np(Converter):\n",
    "    def predicate(self, arg): return isinstance(arg, torch.Tensor)\n",
    "    def formatter(self, arg): return arg.detach().cpu().numpy()\n",
    "torch2np = Torch2np()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np2torch` will convert to tensor with the same `dtype`. It's not as general as `torch2np` since output tensor might need to be on the gpu, but that can be done after.\n",
    "\n",
    "NOTE: The `converted` flag for `np2torch` will not be thread safe, calling `np2torch = Np2Torch()` per invocation should make it safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:46.926780Z",
     "start_time": "2020-07-19T20:48:46.920808Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class Np2torch(Converter):\n",
    "    def predicate(self, arg): return isinstance(arg, np.ndarray)\n",
    "    def formatter(self, arg): return torch.from_numpy(arg)\n",
    "np2torch = Np2torch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpyify` decorator will allow functions designed for torch tensors to also work for numpy tensors. \n",
    "\n",
    "NOTE: this will fail if input does not contain a `np.array` (i.e. like the `eye` function, which takes an integer and returns a tensor). To ensure this works, one of the inputs must be a `np.array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:46.934296Z",
     "start_time": "2020-07-19T20:48:46.929652Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def numpyify(f):\n",
    "    def _numpyify(*args, **kwargs):\n",
    "        np2torch = Np2torch() # For thread safety, make a local copy\n",
    "        args, kwargs = np2torch((args, kwargs))\n",
    "        out = f(*args, **kwargs)\n",
    "        if np2torch.converted: out = torch2np(out)\n",
    "        return out\n",
    "    return _numpyify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`assert_allclose` checks if two things, `A` and `B`, are close to each other. I use `np.allclose` because its more robust than `torch.allclose` (i.e. numpys version will work with datatypes other than `np.array`s, like `bool`s and `int`s)\n",
    "\n",
    "NOTE: I'm assuming the format the inputs is the same; if not I'm assuming this is programmer error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:46.941603Z",
     "start_time": "2020-07-19T20:48:46.936829Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def _assert_allclose(A, B, **kwargs):\n",
    "    if isinstance(A, tuple):            \n",
    "        for a,b in zip(A,B): _assert_allclose(a, b, **kwargs)\n",
    "    elif isinstance(A, dict):           \n",
    "        for key in A.keys() & B.keys(): _assert_allclose(A[key], B[key], **kwargs)\n",
    "    else:\n",
    "        try:    assert(np.allclose(A, B, **kwargs))\n",
    "        except: assert(np.all(A == B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`assert_allclose` converts inputs to torch, because `np.allclose` will fail if inputs are on the gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:46.947538Z",
     "start_time": "2020-07-19T20:48:46.943488Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def assert_allclose(A, B, **kwargs): _assert_allclose(*torch2np((A, B)), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:46.956861Z",
     "start_time": "2020-07-19T20:48:46.948821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4934, 0.6012, 0.8945],\n",
       "         [0.3842, 0.0127, 0.8888],\n",
       "         [0.6677, 0.3990, 0.9536],\n",
       "         [0.2518, 0.5827, 0.8171]]),\n",
       " array([[ 1.79475626, -1.15511211,  0.82222381],\n",
       "        [ 1.1998122 , -2.18561147,  0.54684049],\n",
       "        [-1.27348529, -1.43004744, -0.42254029],\n",
       "        [-0.74613794, -0.22022825, -0.35026096]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand((4,3))\n",
    "B = np.random.normal(size=(4,3))\n",
    "A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:46.962083Z",
     "start_time": "2020-07-19T20:48:46.957839Z"
    }
   },
   "outputs": [],
   "source": [
    "assert_allclose(A, A+1e-5, atol=1e-5)\n",
    "assert_allclose((A, (B, {'test': 1.})), (A+1e-5, (B+1e-5, {'test': 1 + 1e-5})), atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have multiple functions that should work for torch and numpy, we should have a way to test for both without having to write duplicate tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:46.967619Z",
     "start_time": "2020-07-19T20:48:46.962971Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def assert_allclose_f(f, x, y, **kwargs):\n",
    "    if not isinstance(x, tuple): x = (x,)\n",
    "    assert_allclose(f(*x), y, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:46.975999Z",
     "start_time": "2020-07-19T20:48:46.969213Z"
    }
   },
   "outputs": [],
   "source": [
    "# export \n",
    "def assert_allclose_f_ttn(f, x, y, **kwargs): # ttn == \"torch, then numpy\"\n",
    "    torch2np = Torch2np()\n",
    "    assert_allclose_f(f, x, y, **kwargs) # Torch test\n",
    "    x, y = torch2np((x, y))\n",
    "    assert(torch2np.converted)           # Make sure something was converted\n",
    "    assert_allclose_f(f, x, y, **kwargs) # Numpy test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason I can't find a built-in that will reverse and return a list without doing some iterable thing.\n",
    "\n",
    "TODO: get this to work for torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:46.981937Z",
     "start_time": "2020-07-19T20:48:46.977131Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def reverse(A): return A[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:46.987978Z",
     "start_time": "2020-07-19T20:48:46.983220Z"
    }
   },
   "outputs": [],
   "source": [
    "assert_allclose(reverse(['a', 'b', 'c']), ['c', 'b', 'a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shape` returns the tensor shape as a tensor the same type of the tensor. Convenient if you need to do arithmetic based on the size of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:46.994617Z",
     "start_time": "2020-07-19T20:48:46.988970Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def shape(A, dtype=None): \n",
    "    if dtype is None: dtype = A.dtype\n",
    "    return A.new_tensor(A.shape, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.001145Z",
     "start_time": "2020-07-19T20:48:46.995757Z"
    }
   },
   "outputs": [],
   "source": [
    "A = torch.rand(3,4)\n",
    "assert_allclose_f_ttn(shape, A, torch.Tensor([3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.006964Z",
     "start_time": "2020-07-19T20:48:47.002338Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def stackify(A, dim=0):\n",
    "    if isinstance(A, tuple): return torch.stack([stackify(a, dim) for a in A], dim)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.013921Z",
     "start_time": "2020-07-19T20:48:47.007937Z"
    }
   },
   "outputs": [],
   "source": [
    "x = (tuple(torch.Tensor([1,2])), tuple(torch.Tensor([1,2])))\n",
    "assert_allclose_f_ttn(stackify, (x,), torch.Tensor([[1, 2],\n",
    "                                                    [1, 2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch doesnt have an equivalent of `np.delete`\n",
    "\n",
    "NOTE: temporarily not `numpyified` because I need `np.array(,dtype=np.object)` to work since torch does not support jagged/nested tensors yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.019380Z",
     "start_time": "2020-07-19T20:48:47.014993Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def delete(A, idx_delete):\n",
    "    idx = torch.ones(len(A), dtype=torch.bool)\n",
    "    idx[idx_delete] = False\n",
    "    return A[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.026313Z",
     "start_time": "2020-07-19T20:48:47.020354Z"
    }
   },
   "outputs": [],
   "source": [
    "A = torch.Tensor([[1,2,3],\n",
    "                  [4,5,6],\n",
    "                  [7,8,9]])\n",
    "assert_allclose_f_ttn(delete, (A, 1), torch.Tensor([[1, 2, 3],\n",
    "                                                      [7, 8, 9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.031740Z",
     "start_time": "2020-07-19T20:48:47.027328Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def rescale(A, r1, r2):\n",
    "    return (A-r1[0])/(r1[1]-r1[0])*(r2[1]-r2[0])+r2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.041889Z",
     "start_time": "2020-07-19T20:48:47.037722Z"
    }
   },
   "outputs": [],
   "source": [
    "A = torch.Tensor([1,2])\n",
    "assert_allclose_f_ttn(rescale, (A, torch.Tensor([1,2]), torch.Tensor([2,4])), torch.Tensor([2, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Points/Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T19:46:17.283758Z",
     "start_time": "2020-07-19T19:46:17.280117Z"
    }
   },
   "source": [
    "Kind of hard to keep separate distinction between points and vectors even though they technically aren't the same thing because they are represented the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General point stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`singlify` decorator will allow functions designed for multiple points to work for single point inputs. points should have a shape of `[N, [2,3]]` whereas a single point will have shape of `[[2,3]]`, so its convenient to just define the function for multiple points and use the decorator so it will work for a single point.\n",
    "\n",
    "NOTE: first argument must be `ps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.047372Z",
     "start_time": "2020-07-19T20:48:47.044324Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def singlify(f):\n",
    "    def _singlify(ps, *args, **kwargs):\n",
    "        single = len(ps.shape) == 1\n",
    "        if single: ps = ps[None]\n",
    "        ps = f(ps, *args, **kwargs)\n",
    "        if single: ps = ps[0]\n",
    "        return ps\n",
    "    return _singlify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`augment` will add ones to points; useful for affine and homography xforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.053041Z",
     "start_time": "2020-07-19T20:48:47.048426Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "@singlify\n",
    "def augment(ps): return torch.cat([ps, ps.new_ones((len(ps), 1))], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.062109Z",
     "start_time": "2020-07-19T20:48:47.054108Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = torch.Tensor([[0.1940, 0.2536],\n",
    "                   [0.2172, 0.1626],\n",
    "                   [0.9834, 0.2700],\n",
    "                   [0.5324, 0.7137]])\n",
    "assert_allclose_f_ttn(augment, ps, torch.Tensor([[0.1940, 0.2536, 1.0000],\n",
    "                                                 [0.2172, 0.1626, 1.0000],\n",
    "                                                 [0.9834, 0.2700, 1.0000],\n",
    "                                                 [0.5324, 0.7137, 1.0000]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`deaugment` will remove last column; might wanna add check to make sure column contains ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.070724Z",
     "start_time": "2020-07-19T20:48:47.063135Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@singlify\n",
    "def deaugment(ps): return ps[:, 0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.082843Z",
     "start_time": "2020-07-19T20:48:47.071875Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = torch.Tensor([[0.1940, 0.2536, 1.0000],\n",
    "                   [0.2172, 0.1626, 1.0000],\n",
    "                   [0.9834, 0.2700, 1.0000],\n",
    "                   [0.5324, 0.7137, 1.0000]])\n",
    "assert_allclose_f_ttn(deaugment, ps, torch.Tensor([[0.1940, 0.2536],\n",
    "                                                   [0.2172, 0.1626],\n",
    "                                                   [0.9834, 0.2700],\n",
    "                                                   [0.5324, 0.7137]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`normalize` will divide by last column and remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.091263Z",
     "start_time": "2020-07-19T20:48:47.083961Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@singlify\n",
    "def normalize(ps): return deaugment(ps/ps[:, [-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.097662Z",
     "start_time": "2020-07-19T20:48:47.092318Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = torch.Tensor([[0.1940, 0.2536, 2.0000],\n",
    "                   [0.2172, 0.1626, 3.0000],\n",
    "                   [0.9834, 0.2700, 4.0000],\n",
    "                   [0.5324, 0.7137, 5.0000]])\n",
    "assert_allclose_f_ttn(normalize, ps, torch.Tensor([[0.0970, 0.1268],\n",
    "                                                   [0.0724, 0.0542],\n",
    "                                                   [0.2458, 0.0675],\n",
    "                                                   [0.1065, 0.1427]]), atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T18:07:45.252228Z",
     "start_time": "2020-07-19T18:07:45.249778Z"
    }
   },
   "source": [
    "## Bounding box stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: for bounding boxes, I'm not sure if the dtype should always be `long`, which works for most cases except for `ps_bb`, which can have a non-integer bounding box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T00:03:08.202947Z",
     "start_time": "2020-05-26T00:03:08.198828Z"
    }
   },
   "source": [
    "`ps_bb` is points bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.103506Z",
     "start_time": "2020-07-19T20:48:47.098742Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def ps_bb(ps): return stackify((torch.min(ps, dim=0).values, torch.max(ps, dim=0).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.109862Z",
     "start_time": "2020-07-19T20:48:47.104477Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = torch.Tensor([[0.1940, 0.2536],\n",
    "                   [0.2172, 0.1626],\n",
    "                   [0.9834, 0.2700],\n",
    "                   [0.5324, 0.7137]])\n",
    "assert_allclose_f_ttn(ps_bb, ps, torch.Tensor([[0.194 , 0.1626],\n",
    "                                               [0.9834, 0.7137]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`array_bb` is array bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.117006Z",
     "start_time": "2020-07-19T20:48:47.112182Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def array_bb(arr): return torch.LongTensor([[0,0], [arr.shape[1]-1, arr.shape[0]-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.123351Z",
     "start_time": "2020-07-19T20:48:47.118023Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = torch.rand(5,4)\n",
    "assert_allclose_f_ttn(array_bb, arr, torch.LongTensor([[0, 0],\n",
    "                                                       [3, 4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bb_sz` returns the size of a bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.129822Z",
     "start_time": "2020-07-19T20:48:47.124330Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def bb_sz(bb): return torch.LongTensor([bb[1,1]-bb[0,1]+1, bb[1,0]-bb[0,0]+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.136667Z",
     "start_time": "2020-07-19T20:48:47.130773Z"
    }
   },
   "outputs": [],
   "source": [
    "bb = torch.LongTensor([[0,0],[5,4]])\n",
    "assert_allclose_f_ttn(bb_sz, bb, torch.LongTensor([5, 6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bb_grid` is bounding box grid; i,j is swapped to x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.142102Z",
     "start_time": "2020-07-19T20:48:47.137661Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def bb_grid(bb, dtype):\n",
    "    return stackify(reverse(torch.meshgrid(torch.arange(bb[0,1],bb[1,1]+1, dtype=dtype), \n",
    "                                           torch.arange(bb[0,0],bb[1,0]+1, dtype=dtype))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.148695Z",
     "start_time": "2020-07-19T20:48:47.143305Z"
    }
   },
   "outputs": [],
   "source": [
    "bb = torch.LongTensor([[0,0],[2,1]])\n",
    "assert_allclose_f_ttn(bb_grid, (bb, torch.float), torch.Tensor([[[0, 1, 2],\n",
    "                                                                 [0, 1, 2]],\n",
    "                                                                [[0, 0, 0],\n",
    "                                                                 [1, 1, 1]]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bb_array` applies bounding box to array and returns the sub array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.154238Z",
     "start_time": "2020-07-19T20:48:47.149565Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def bb_array(arr, bb): return arr[bb[0,1]:bb[1,1]+1, bb[0,0]:bb[1,0]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.160568Z",
     "start_time": "2020-07-19T20:48:47.155226Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = torch.Tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "bb = torch.LongTensor([[1,1],[2,2]])\n",
    "assert_allclose_f_ttn(bb_array, (arr, bb), torch.Tensor([[5, 6],\n",
    "                                                         [8, 9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.166521Z",
     "start_time": "2020-07-19T20:48:47.161949Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def is_p_in_bb(p, bb): return p[0] >= bb[0,0] and p[1] >= bb[0,1] and p[0] <= bb[1,0] and p[1] <= bb[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.172361Z",
     "start_time": "2020-07-19T20:48:47.167626Z"
    }
   },
   "outputs": [],
   "source": [
    "p1 = torch.Tensor([0.0, 0.0])\n",
    "p2 = torch.Tensor([1.5, 1.5])\n",
    "bb = torch.Tensor([[1,1],\n",
    "                   [2,2]])\n",
    "assert_allclose_f_ttn(is_p_in_bb, (p1, bb), False)\n",
    "assert_allclose_f_ttn(is_p_in_bb, (p2, bb), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.177691Z",
     "start_time": "2020-07-19T20:48:47.173402Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def is_bb_in_bb(bb1, bb2): return is_p_in_bb(bb1[0], bb2) and is_p_in_bb(bb1[1], bb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.186814Z",
     "start_time": "2020-07-19T20:48:47.178559Z"
    }
   },
   "outputs": [],
   "source": [
    "bb1 = torch.Tensor([[1,1],[5,5]])\n",
    "bb2 = torch.Tensor([[2,2],[4,4]])\n",
    "bb3 = torch.Tensor([[8,8],[9,9]])\n",
    "assert_allclose_f_ttn(is_bb_in_bb, (bb2, bb1), True)\n",
    "assert_allclose_f_ttn(is_bb_in_bb, (bb3, bb1), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boundary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.195147Z",
     "start_time": "2020-07-19T20:48:47.187808Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def is_p_in_b(p, b): return Polygon(b).contains(Point(*p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.201805Z",
     "start_time": "2020-07-19T20:48:47.196368Z"
    }
   },
   "outputs": [],
   "source": [
    "b  = torch.Tensor([[0,0],[0,1],[1,1],[1,0]])\n",
    "p1 = torch.Tensor([0.5, 0.5])\n",
    "p2 = torch.Tensor([1.5, 1.5])\n",
    "assert_allclose_f_ttn(is_p_in_b, (p1, b), True)\n",
    "assert_allclose_f_ttn(is_p_in_b, (p2, b), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point geometries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grid2ps` converts grid to points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.206749Z",
     "start_time": "2020-07-19T20:48:47.202797Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def grid2ps(X, Y, order='row'):\n",
    "    if   order == 'row': return stackify((X.flatten(), Y.flatten()), dim=1)\n",
    "    elif order == 'col': return grid2ps(X.T, Y.T, order='row')\n",
    "    else: raise RuntimeError(f'Unrecognized option: {order}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.213848Z",
     "start_time": "2020-07-19T20:48:47.207854Z"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.Tensor([[1,2],[1,2]])\n",
    "Y = torch.Tensor([[1,1],[2,2]])\n",
    "assert_allclose_f_ttn(grid2ps, (X, Y, 'row'), torch.Tensor([[1, 1],\n",
    "                                                            [2, 1],\n",
    "                                                            [1, 2],\n",
    "                                                            [2, 2]]))\n",
    "assert_allclose_f_ttn(grid2ps, (X, Y, 'col'), torch.Tensor([[1, 1],\n",
    "                                                            [1, 2],\n",
    "                                                            [2, 1],\n",
    "                                                            [2, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.218997Z",
     "start_time": "2020-07-19T20:48:47.215163Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def array_ps(arr, dtype=None): \n",
    "    if dtype is None: dtype = arr.dtype\n",
    "    return grid2ps(*bb_grid(array_bb(arr), dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.225831Z",
     "start_time": "2020-07-19T20:48:47.220035Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = torch.rand(3,2)\n",
    "assert_allclose_f_ttn(array_ps, arr, torch.Tensor([[0, 0],\n",
    "                                                   [1, 0],\n",
    "                                                   [0, 1],\n",
    "                                                   [1, 1],\n",
    "                                                   [0, 2],\n",
    "                                                   [1, 2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`crrgrid` is centered rectanglular rectangle grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.231362Z",
     "start_time": "2020-07-19T20:48:47.227085Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def crrgrid(p):\n",
    "    num_h, num_w, spacing_h, spacing_w = p\n",
    "    h, w = spacing_h*(num_h-1), spacing_w*(num_w-1)\n",
    "    return grid2ps(*reverse(torch.meshgrid(torch.linspace(-h/2, h/2, int(num_h), dtype=p.dtype),\n",
    "                                           torch.linspace(-w/2, w/2, int(num_w), dtype=p.dtype))), \n",
    "                   'col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.240192Z",
     "start_time": "2020-07-19T20:48:47.232429Z"
    }
   },
   "outputs": [],
   "source": [
    "assert_allclose_f_ttn(crrgrid, torch.Tensor([2, 2, 1, 1]), torch.Tensor([[-0.5000, -0.5000],\n",
    "                                                                         [-0.5000,  0.5000],\n",
    "                                                                         [ 0.5000, -0.5000],\n",
    "                                                                         [ 0.5000,  0.5000]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`csrgrid` is centered square rectangle grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.245544Z",
     "start_time": "2020-07-19T20:48:47.241256Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def csrgrid(p):\n",
    "    num_h, num_w, spacing = p\n",
    "    return crrgrid(stackify((num_h, num_w, spacing, spacing)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.252437Z",
     "start_time": "2020-07-19T20:48:47.246930Z"
    }
   },
   "outputs": [],
   "source": [
    "assert_allclose_f_ttn(csrgrid, torch.Tensor([2, 2, 1]), torch.Tensor([[-0.5, -0.5],\n",
    "                                                                      [-0.5,  0.5],\n",
    "                                                                      [ 0.5, -0.5],\n",
    "                                                                      [ 0.5,  0.5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T21:15:26.373537Z",
     "start_time": "2020-07-08T21:15:26.364762Z"
    }
   },
   "source": [
    "`csdgrid` is centered square diamond grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.259570Z",
     "start_time": "2020-07-19T20:48:47.253506Z"
    }
   },
   "outputs": [],
   "source": [
    "# export \n",
    "@numpyify\n",
    "def csdgrid(p): # Pretty sure this implementation can be vastly improved\n",
    "    num_h, num_w, spacing, fo = p\n",
    "    h, w = spacing*(num_h-1), spacing*(num_w-1)\n",
    "    xs_grid = torch.linspace(-w/2, w/2, int(num_w))\n",
    "    ys_grid = torch.linspace(-h/2, h/2, int(num_h))\n",
    "    ps = []\n",
    "    for x_grid in xs_grid:\n",
    "        if fo: ys, fo = ys_grid[0::2], False\n",
    "        else:  ys, fo = ys_grid[1::2], True\n",
    "        xs = x_grid.new_full((len(ys),), x_grid)\n",
    "        ps.append(stackify((xs, ys), dim=1))\n",
    "    return torch.cat(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.266669Z",
     "start_time": "2020-07-19T20:48:47.260724Z"
    }
   },
   "outputs": [],
   "source": [
    "assert_allclose_f_ttn(csdgrid, torch.Tensor([5, 4, 1, True]), torch.Tensor([[-1.5, -2],\n",
    "                                                                            [-1.5,  0],\n",
    "                                                                            [-1.5,  2],\n",
    "                                                                            [-0.5, -1],\n",
    "                                                                            [-0.5,  1],\n",
    "                                                                            [ 0.5, -2],\n",
    "                                                                            [ 0.5,  0],\n",
    "                                                                            [ 0.5,  2],\n",
    "                                                                            [ 1.5, -1],\n",
    "                                                                            [ 1.5,  1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cfpgrid` is centered four point grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.274247Z",
     "start_time": "2020-07-19T20:48:47.267747Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def cfpgrid(p):\n",
    "    two = p.new_tensor(2)\n",
    "    h, w = p\n",
    "    return crrgrid(stackify((two, two, h, w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.281492Z",
     "start_time": "2020-07-19T20:48:47.275322Z"
    }
   },
   "outputs": [],
   "source": [
    "assert_allclose_f_ttn(cfpgrid, torch.Tensor([2,2]), torch.Tensor([[-1, -1],\n",
    "                                                                  [-1,  1],\n",
    "                                                                  [ 1, -1],\n",
    "                                                                  [ 1,  1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General vector stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T02:00:08.716743Z",
     "start_time": "2020-05-26T02:00:08.710841Z"
    }
   },
   "source": [
    "`unitize` will make norm of each vector 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.286283Z",
     "start_time": "2020-07-19T20:48:47.282547Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@singlify\n",
    "@numpyify\n",
    "def unitize(vs): return vs/torch.norm(vs, dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.292803Z",
     "start_time": "2020-07-19T20:48:47.287230Z"
    }
   },
   "outputs": [],
   "source": [
    "vs = torch.Tensor([[0.1940, 0.2536],\n",
    "                   [0.2172, 0.1626],\n",
    "                   [0.9834, 0.2700],\n",
    "                   [0.5324, 0.7137]])\n",
    "assert_allclose_f_ttn(unitize, vs, torch.Tensor([[0.6075896, 0.7942511],\n",
    "                                                 [0.8005304, 0.5992921],\n",
    "                                                 [0.9643143, 0.2647598],\n",
    "                                                 [0.5979315, 0.8015471]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.298152Z",
     "start_time": "2020-07-19T20:48:47.293957Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def cross_mat(v):\n",
    "    zero = v.new_tensor(0)\n",
    "    return stackify((( zero, -v[2],  v[1]),\n",
    "                     ( v[2],  zero, -v[0]),\n",
    "                     (-v[1],  v[0],  zero)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.307392Z",
     "start_time": "2020-07-19T20:48:47.299136Z"
    }
   },
   "outputs": [],
   "source": [
    "v = torch.Tensor([1,2,3])\n",
    "assert_allclose_f_ttn(cross_mat, v, torch.Tensor([[ 0,-3, 2],\n",
    "                                                  [ 3, 0,-1],\n",
    "                                                  [-2, 1, 0]]))\n",
    "assert_allclose(cross_mat(v)@v, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pmm` is point matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.312305Z",
     "start_time": "2020-07-19T20:48:47.308422Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@singlify\n",
    "def pmm(ps, A, aug=False):\n",
    "    if aug: ps = augment(ps)\n",
    "    ps = (A@ps.T).T\n",
    "    if aug: ps = normalize(ps) # works for both affine and homography transforms\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.318694Z",
     "start_time": "2020-07-19T20:48:47.313519Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = torch.Tensor([[0.1940, 0.2536],\n",
    "                   [0.2172, 0.1626],\n",
    "                   [0.9834, 0.2700],\n",
    "                   [0.5324, 0.7137]])\n",
    "A = torch.Tensor([[0.9571, 0.5551],\n",
    "                  [0.8914, 0.2626]])\n",
    "assert_allclose_f_ttn(pmm, (ps, A), torch.Tensor([[0.3265, 0.2395],\n",
    "                                                  [0.2981, 0.2363],\n",
    "                                                  [1.0911, 0.9475],\n",
    "                                                  [0.9057, 0.6620]]), atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spherical coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.324275Z",
     "start_time": "2020-07-19T20:48:47.319691Z"
    }
   },
   "outputs": [],
   "source": [
    "@singlify\n",
    "@numpyify\n",
    "def cart2spherical(ps):\n",
    "    x, y, z = ps[:,0], ps[:,1], ps[:,2]\n",
    "    r = torch.sqrt(x**2 + y**2 + z**2)\n",
    "    theta = torch.atan2(np.sqrt(x**2 + y**2), z)\n",
    "    phi = torch.atan2(y, x)\n",
    "    return stackify((r, theta, phi), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.331229Z",
     "start_time": "2020-07-19T20:48:47.325155Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = torch.Tensor([[0.4082785 , 0.1256695 , 0.54343185],\n",
    "                   [0.93478803, 0.40557636, 0.40224384],\n",
    "                   [0.48831708, 0.82743735, 0.68537884]])\n",
    "assert_allclose_f_ttn(cart2spherical, ps, torch.Tensor([[0.69123247, 0.66619615, 0.29860039],\n",
    "                                                        [1.09550032, 1.19482283, 0.40935945],\n",
    "                                                        [1.18019079, 0.95116431, 1.03764654]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.336772Z",
     "start_time": "2020-07-19T20:48:47.332243Z"
    }
   },
   "outputs": [],
   "source": [
    "@singlify\n",
    "@numpyify\n",
    "def spherical2cart(ps):\n",
    "    r, theta, phi = ps[:,0], ps[:,1], ps[:,2]\n",
    "    x = r*torch.sin(theta)*torch.cos(phi)\n",
    "    y = r*torch.sin(theta)*torch.sin(phi)\n",
    "    z = r*torch.cos(theta)\n",
    "    return stackify((x, y, z), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.346202Z",
     "start_time": "2020-07-19T20:48:47.342324Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = torch.Tensor([[0.69123247, 0.66619615, 0.29860039],\n",
    "                   [1.09550032, 1.19482283, 0.40935945],\n",
    "                   [1.18019079, 0.95116431, 1.03764654]])\n",
    "assert_allclose_f_ttn(spherical2cart, ps, torch.Tensor([[0.4082785 , 0.1256695 , 0.5434318 ],\n",
    "                                                        [0.9347881 , 0.4055764 , 0.40224388],\n",
    "                                                        [0.4883171 , 0.82743734, 0.68537885]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.352591Z",
     "start_time": "2020-07-19T20:48:47.349007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00793236, 0.51678762, 0.74195313],\n",
       "       [0.31894378, 0.37193991, 0.4933561 ],\n",
       "       [0.59464409, 0.19142391, 0.95325643],\n",
       "       [0.61989835, 0.04268255, 0.48770974]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = np.random.uniform(size=(4,3))\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.358098Z",
     "start_time": "2020-07-19T20:48:47.353441Z"
    }
   },
   "outputs": [],
   "source": [
    "assert_allclose(ps, spherical2cart(cart2spherical(ps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`condition_mat` is typically used to \"condition\" points to improve conditioning; its inverse is usually applied afterwards. It sets the mean of the points to zero and the average distance to `sqrt(2)`. I use the term \"condition\" here so I don't get confused with \"normalization\" which is used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.364235Z",
     "start_time": "2020-07-19T20:48:47.359128Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def condition_mat(ps):\n",
    "    zero, one = ps.new_tensor(0), ps.new_tensor(1)\n",
    "\n",
    "    xs, ys = ps[:, 0], ps[:, 1]\n",
    "    mean_x, mean_y = xs.mean(), ys.mean()\n",
    "    s_m = math.sqrt(2)*len(ps)/(torch.sqrt((xs-mean_x)**2+(ys-mean_y)**2)).sum()\n",
    "    return stackify((( s_m, zero, -mean_x*s_m),\n",
    "                     (zero,  s_m, -mean_y*s_m),\n",
    "                     (zero, zero,         one)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.370956Z",
     "start_time": "2020-07-19T20:48:47.365296Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = torch.Tensor([[0.5466, 0.0889],\n",
    "                   [0.1493, 0.6591],\n",
    "                   [0.5600, 0.0352],\n",
    "                   [0.7287, 0.5892]])\n",
    "assert_allclose_f_ttn(condition_mat, ps, torch.Tensor([[ 4.0950,  0.0000, -2.0317],\n",
    "                                                       [ 0.0000,  4.0950, -1.4050],\n",
    "                                                       [ 0.0000,  0.0000,  1.0000]]), atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.375914Z",
     "start_time": "2020-07-19T20:48:47.371950Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def condition(ps):\n",
    "    T = condition_mat(ps)\n",
    "    return pmm(ps, T, aug=True), T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.382986Z",
     "start_time": "2020-07-19T20:48:47.377104Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = torch.Tensor([[0.5466, 0.0889],\n",
    "                   [0.1493, 0.6591],\n",
    "                   [0.5600, 0.0352],\n",
    "                   [0.7287, 0.5892]])\n",
    "ps_cond, T = condition(ps)\n",
    "assert_allclose(ps_cond.mean(), 0, atol=1e-6)\n",
    "assert_allclose(ps_cond.norm(dim=1).mean(), math.sqrt(2), atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homographies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`homography` estimates a homography between two sets of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.387937Z",
     "start_time": "2020-07-19T20:48:47.384093Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def homography(ps1, ps2):    \n",
    "    # Condition and augment points\n",
    "    (ps1_cond, T1), (ps2_cond, T2) = map(condition, [ps1, ps2])\n",
    "    ps1_cond, ps2_cond = map(augment, [ps1_cond, ps2_cond])\n",
    "    \n",
    "    # Form homogeneous system\n",
    "    L = torch.cat([torch.cat([ps1_cond, torch.zeros_like(ps1_cond), -ps2_cond[:, 0:1]*ps1_cond], dim=1),\n",
    "                   torch.cat([torch.zeros_like(ps1_cond), ps1_cond, -ps2_cond[:, 1:2]*ps1_cond], dim=1)])\n",
    "\n",
    "    # Solution is the last column of V\n",
    "    H12_cond = torch.svd(L, some=False).V[:,-1].reshape(3,3)\n",
    "    \n",
    "    # Undo conditioning\n",
    "    H12 = torch.inverse(T2)@H12_cond@T1\n",
    "    H12 = H12/H12[2,2] # Sets H12[2,2] to 1\n",
    "    return H12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.399220Z",
     "start_time": "2020-07-19T20:48:47.388907Z"
    }
   },
   "outputs": [],
   "source": [
    "ps1 = torch.Tensor([[-350, -350],\n",
    "                    [-350,  350],\n",
    "                    [ 350, -350],\n",
    "                    [ 350,  350]])\n",
    "ps2 = torch.Tensor([[ 970,  517],\n",
    "                    [ 156,  498],\n",
    "                    [ 973, 1317],\n",
    "                    [ 192, 1279]])\n",
    "assert_allclose_f_ttn(homography, (ps1, ps2), torch.Tensor([[ 6.252e-02, -1.117e+00,  5.6786e+02],\n",
    "                                                            [ 1.183e+00, -8.049e-03,  9.1087e+02],\n",
    "                                                            [ 6.000e-05,  3.650e-05,  1.0000e+00]]), atol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`approx_R` gives the nearest rotational approximation to the input matrix (I believe frobenium norm). Note that for a proper rotation determinant must be +1, which is checked after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.403021Z",
     "start_time": "2020-07-19T20:48:47.400225Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def approx_R(R):\n",
    "    [U,_,V] = torch.svd(R)\n",
    "    R = U@V.T\n",
    "    if not torch.isclose(torch.det(R), R.new_tensor(1)):\n",
    "        R = R.new_full((3,3), math.nan)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.409674Z",
     "start_time": "2020-07-19T20:48:47.404039Z"
    }
   },
   "outputs": [],
   "source": [
    "R = torch.Tensor([[0.0958, 0.8441, 0.2009],\n",
    "                  [0.7877, 0.9110, 0.9277],\n",
    "                  [0.3727, 0.7262, 0.1417]])\n",
    "assert_allclose_f_ttn(approx_R, R, torch.Tensor([[-0.5659,  0.8152,  0.1237],\n",
    "                                                 [ 0.5155,  0.2328,  0.8247],\n",
    "                                                 [ 0.6434,  0.5304, -0.5520]]), atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T13:31:59.556732Z",
     "start_time": "2020-07-19T13:31:59.553682Z"
    }
   },
   "source": [
    "#### Euler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.416864Z",
     "start_time": "2020-07-19T20:48:47.411396Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def euler2R(euler):\n",
    "    s, c = torch.sin, torch.cos\n",
    "    e_x, e_y, e_z = euler\n",
    "    return stackify((\n",
    "        (c(e_y)*c(e_z), c(e_z)*s(e_x)*s(e_y) - c(e_x)*s(e_z), s(e_x)*s(e_z) + c(e_x)*c(e_z)*s(e_y)),\n",
    "        (c(e_y)*s(e_z), c(e_x)*c(e_z) + s(e_x)*s(e_y)*s(e_z), c(e_x)*s(e_y)*s(e_z) - c(e_z)*s(e_x)),\n",
    "        (      -s(e_y),                        c(e_y)*s(e_x),                        c(e_x)*c(e_y))\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.425620Z",
     "start_time": "2020-07-19T20:48:47.417967Z"
    }
   },
   "outputs": [],
   "source": [
    "euler = torch.Tensor([0.2748, 0.0352, 0.4496])\n",
    "assert_allclose_f_ttn(euler2R, euler, torch.Tensor([[ 0.9001, -0.4097,  0.1484],\n",
    "                                                    [ 0.4343,  0.8710, -0.2297],\n",
    "                                                    [-0.0352,  0.2712,  0.9619]]), atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.430819Z",
     "start_time": "2020-07-19T20:48:47.426635Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def R2euler(R):\n",
    "    return stackify((torch.atan2( R[2, 1], R[2, 2]),\n",
    "                     torch.atan2(-R[2, 0], torch.sqrt(R[0, 0]**2+R[1, 0]**2)),\n",
    "                     torch.atan2( R[1, 0], R[0, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.437455Z",
     "start_time": "2020-07-19T20:48:47.431855Z"
    }
   },
   "outputs": [],
   "source": [
    "R = torch.Tensor([[ 0.9001, -0.4097,  0.1484],\n",
    "                  [ 0.4343,  0.8710, -0.2297],\n",
    "                  [-0.0352,  0.2712,  0.9619]])\n",
    "assert_allclose_f_ttn(R2euler, R, torch.Tensor([0.2748, 0.0352, 0.4496]), atol=1e-4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensure euler => R => euler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.442908Z",
     "start_time": "2020-07-19T20:48:47.438447Z"
    }
   },
   "outputs": [],
   "source": [
    "euler = torch.Tensor([0.2748, 0.0352, 0.4496])\n",
    "assert_allclose(R2euler(euler2R(euler)), euler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rodrigues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rodrigues conversion from:\n",
    "* https://www2.cs.duke.edu/courses/fall13/compsci527/notes/rodrigues.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.448340Z",
     "start_time": "2020-07-19T20:48:47.443999Z"
    }
   },
   "outputs": [],
   "source": [
    "@numpyify\n",
    "def rodrigues2R(r):\n",
    "    zero = r.new_tensor(0)\n",
    "    \n",
    "    theta = torch.norm(r)\n",
    "    if theta > math.pi: warnings.warn('Theta greater than pi')\n",
    "    if torch.isclose(theta, zero): return torch.eye(3, dtype=r.type)\n",
    "    u = r/theta\n",
    "    return torch.eye(3, dtype=r.dtype)*torch.cos(theta) + \\\n",
    "           (1-torch.cos(theta))*u[:,None]@u[:,None].T + \\\n",
    "           cross_mat(u)*torch.sin(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.455178Z",
     "start_time": "2020-07-19T20:48:47.449472Z"
    }
   },
   "outputs": [],
   "source": [
    "theta = math.pi/4\n",
    "k = torch.Tensor([ 0.8155,  0.0937, -0.5711])\n",
    "r = theta*k\n",
    "assert_allclose_f_ttn(rodrigues2R, r, torch.Tensor([[ 0.9019,  0.4262, -0.0702],\n",
    "                                                    [-0.3814,  0.7097, -0.5923],\n",
    "                                                    [-0.2027,  0.5610,  0.8026]]), atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.462646Z",
     "start_time": "2020-07-19T20:48:47.456191Z"
    }
   },
   "outputs": [],
   "source": [
    "@numpyify\n",
    "def R2rodrigues(R):\n",
    "    zero, one, pi = R.new_tensor(0), R.new_tensor(1), R.new_tensor(math.pi)\n",
    "    \n",
    "    A = (R-R.T)/2\n",
    "    rho = A[[2,0,1],[1,2,0]]\n",
    "    s = torch.norm(rho)\n",
    "    c = (R.trace()-1)/2\n",
    "    if torch.isclose(s, zero) and torch.isclose(c, one): \n",
    "        r = R.new_zeros(3)\n",
    "    elif torch.isclose(s, zero) and torch.isclose(c, -one):\n",
    "        V = R + torch.eye(3, dtype=R.dtype)\n",
    "        v = V[:, torch.where(~torch.isclose(torch.norm(V, dim=0), zero))[0][0]] # Just get first non-zero\n",
    "        u = unitize(v)\n",
    "        def S_half(r):\n",
    "            if torch.isclose(torch.norm(r), pi) and \\\n",
    "               ((torch.isclose(r[0], zero) and torch.isclose(r[1], zero) and r[2] < 0) or \\\n",
    "                (torch.isclose(r[0], zero) and r[1] < 0) or \\\n",
    "                (r[0] < 0)):\n",
    "                return -r\n",
    "            else: \n",
    "                return r\n",
    "        r = S_half(u*math.pi)\n",
    "    elif not torch.isclose(s, zero):\n",
    "        u = rho/s\n",
    "        theta = torch.atan2(s,c)\n",
    "        r = u*theta\n",
    "    else: raise RuntimeError('This shouldnt happen; please debug')\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.469154Z",
     "start_time": "2020-07-19T20:48:47.464040Z"
    }
   },
   "outputs": [],
   "source": [
    "R = torch.Tensor([[ 0.9019,  0.4262, -0.0702],\n",
    "                  [-0.3814,  0.7097, -0.5923],\n",
    "                  [-0.2027,  0.5610,  0.8026]])\n",
    "assert_allclose_f_ttn(R2rodrigues, R, torch.tensor([ 0.6405,  0.0736, -0.4485]), atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.474644Z",
     "start_time": "2020-07-19T20:48:47.470357Z"
    }
   },
   "outputs": [],
   "source": [
    "r = torch.Tensor([.1,.2,.3])\n",
    "assert_allclose(R2rodrigues(rodrigues2R(r)), r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other rotation stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`approx_R` gives the nearest rotational approximation to the input matrix (I believe frobenium norm). Note that for a proper rotation determinant must be +1, which is checked after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.479928Z",
     "start_time": "2020-07-19T20:48:47.475699Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def approx_R(R):\n",
    "    [U,_,V] = torch.svd(R)\n",
    "    R = U@V.T\n",
    "    if not torch.isclose(torch.det(R), R.new_tensor(1)):\n",
    "        R = R.new_full((3,3), math.nan)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.486865Z",
     "start_time": "2020-07-19T20:48:47.481051Z"
    }
   },
   "outputs": [],
   "source": [
    "R = torch.Tensor([[0.0958, 0.8441, 0.2009],\n",
    "                  [0.7877, 0.9110, 0.9277],\n",
    "                  [0.3727, 0.7262, 0.1417]])\n",
    "assert_allclose_f_ttn(approx_R, R, torch.Tensor([[-0.5659,  0.8152,  0.1237],\n",
    "                                                 [ 0.5155,  0.2328,  0.8247],\n",
    "                                                 [ 0.6434,  0.5304, -0.5520]]), atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rigid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rigid transforms are a rotation followed by translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.494473Z",
     "start_time": "2020-07-19T20:48:47.487830Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def Rt2M(R, t):\n",
    "    assert_allclose(R.dtype, t.dtype)\n",
    "    M = torch.cat([R, t[:,None]], dim=1)\n",
    "    M = torch.cat([M, M.new_tensor([[0,0,0,1]])])\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.500924Z",
     "start_time": "2020-07-19T20:48:47.495536Z"
    }
   },
   "outputs": [],
   "source": [
    "R = torch.Tensor([[-0.5659,  0.8152,  0.1237],\n",
    "                  [ 0.5155,  0.2328,  0.8247],\n",
    "                  [ 0.6434,  0.5304, -0.5520]])\n",
    "t = torch.Tensor([1,2,3])\n",
    "assert_allclose_f_ttn(Rt2M, (R,t), torch.Tensor([[-0.5659,  0.8152,  0.1237,  1.0000],\n",
    "                                                 [ 0.5155,  0.2328,  0.8247,  2.0000],\n",
    "                                                 [ 0.6434,  0.5304, -0.5520,  3.0000],\n",
    "                                                 [ 0.0000,  0.0000,  0.0000,  1.0000]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.506131Z",
     "start_time": "2020-07-19T20:48:47.502006Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def M2Rt(M): return M[0:3,0:3], M[0:3,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.512931Z",
     "start_time": "2020-07-19T20:48:47.507030Z"
    }
   },
   "outputs": [],
   "source": [
    "M = torch.Tensor([[-0.5659,  0.8152,  0.1237,  1.0000],\n",
    "                  [ 0.5155,  0.2328,  0.8247,  2.0000],\n",
    "                  [ 0.6434,  0.5304, -0.5520,  3.0000],\n",
    "                  [ 0.0000,  0.0000,  0.0000,  1.0000]])\n",
    "assert_allclose_f_ttn(M2Rt, M, (torch.Tensor([[-0.5659,  0.8152,  0.1237],\n",
    "                                              [ 0.5155,  0.2328,  0.8247],\n",
    "                                              [ 0.6434,  0.5304, -0.5520]]),\n",
    "                                torch.Tensor([1,2,3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.518117Z",
     "start_time": "2020-07-19T20:48:47.514063Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def invert_rigid(M):\n",
    "    R, t = M2Rt(M)\n",
    "    return Rt2M(R.T, -R.T@t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.524285Z",
     "start_time": "2020-07-19T20:48:47.519309Z"
    }
   },
   "outputs": [],
   "source": [
    "M = torch.Tensor([[-0.5659,  0.8152,  0.1237,  1.0000],\n",
    "                  [ 0.5155,  0.2328,  0.8247,  2.0000],\n",
    "                  [ 0.6434,  0.5304, -0.5520,  3.0000],\n",
    "                  [ 0.0000,  0.0000,  0.0000,  1.0000]])\n",
    "assert_allclose_f_ttn(invert_rigid, M, torch.inverse(M), atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.531989Z",
     "start_time": "2020-07-19T20:48:47.525300Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def mult_rigid(M1, M2):\n",
    "    assert_allclose(M1.dtype, M2.dtype)\n",
    "    R1, t1 = M2Rt(M1)\n",
    "    R2, t2 = M2Rt(M2)\n",
    "    return Rt2M(R1@R2, R1@t2+t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.538752Z",
     "start_time": "2020-07-19T20:48:47.533473Z"
    }
   },
   "outputs": [],
   "source": [
    "M = torch.Tensor([[-0.5659,  0.8152,  0.1237,  1.0000],\n",
    "                  [ 0.5155,  0.2328,  0.8247,  2.0000],\n",
    "                  [ 0.6434,  0.5304, -0.5520,  3.0000],\n",
    "                  [ 0.0000,  0.0000,  0.0000,  1.0000]])\n",
    "assert_allclose_f_ttn(mult_rigid, (M,M), M@M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Vector stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuff placed here mainly because it requires stuff from transforms section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a random unit vector uniformly sampled over a sphere, if you randomly sample `theta` and `phi` directly, you will over sample near the poles. Instead, you can do an \"equal area\" projection of the sphere onto a cylinder (i.e. rectangle), uniformly sample the cylinder/rectangle, and then project the point back. More info here:\n",
    "* https://math.stackexchange.com/a/44691\n",
    "\n",
    "NOTE: `torch.rand` is random uniform between `[0,1)`, so it is rescaled as needed. Also, since `random_unit` doesnt take in a `tensor`, it cannot be `numpyified`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.543996Z",
     "start_time": "2020-07-19T20:48:47.539776Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_unit(dtype):\n",
    "    r = torch.ones(1, dtype=dtype)\n",
    "    theta = torch.acos(rescale(torch.rand(1, dtype=dtype), [0,1], [-1,1]))\n",
    "    phi = rescale(torch.rand(1, dtype=dtype), [0,1], [0, 2*math.pi])\n",
    "    return spherical2cart(torch.cat((r, theta, phi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.550488Z",
     "start_time": "2020-07-19T20:48:47.545018Z"
    }
   },
   "outputs": [],
   "source": [
    "assert_allclose(torch.norm(random_unit(torch.float)), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`v_v_angle` is vector-vector angle and returns the angle between two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.558573Z",
     "start_time": "2020-07-19T20:48:47.551504Z"
    }
   },
   "outputs": [],
   "source": [
    "@numpyify\n",
    "def v_v_angle(a, b): return torch.acos(torch.dot(a,b)/(torch.norm(a)*torch.norm(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.568029Z",
     "start_time": "2020-07-19T20:48:47.559600Z"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.Tensor([ 0.5568, -0.4851, -0.6743])\n",
    "b = torch.Tensor([-0.8482, -0.4175, -0.3260])\n",
    "assert_allclose_f_ttn(v_v_angle, (a, b), 1.6207424465344742, atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T17:45:09.147783Z",
     "start_time": "2020-07-19T17:45:09.144252Z"
    }
   },
   "source": [
    "`v_v_R` is vector vector rotation matrix and returns the rotation matrix between the two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.576108Z",
     "start_time": "2020-07-19T20:48:47.569089Z"
    }
   },
   "outputs": [],
   "source": [
    "@numpyify\n",
    "def v_v_R(v1, v2):\n",
    "    theta = v_v_angle(v1, v2)\n",
    "    v3 = unitize(torch.cross(v1, v2))\n",
    "    return rodrigues2R(theta*v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.586676Z",
     "start_time": "2020-07-19T20:48:47.577405Z"
    }
   },
   "outputs": [],
   "source": [
    "v1 = torch.Tensor([ 0.5568, -0.4851, -0.6743])\n",
    "v2 = torch.Tensor([-0.8482, -0.4175, -0.3260])\n",
    "assert_allclose_f_ttn(v_v_R, (v1,v2), torch.Tensor([[-0.03390428,  0.54606884,  0.83705395],\n",
    "                                                    [-0.74174788,  0.54757324, -0.3872643 ],\n",
    "                                                    [-0.66982131, -0.63401291,  0.38648033]]))\n",
    "assert_allclose(unitize(pmm(v1, v_v_R(v1,v2))), unitize(v2), atol=1e-4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.590417Z",
     "start_time": "2020-07-19T20:48:47.587722Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def pm2l(p, m):\n",
    "    zero, one = p.new_tensor(0), p.new_tensor(1)\n",
    "    \n",
    "    x, y = p\n",
    "    if not torch.isfinite(m): a, b, c = one, zero,    -x\n",
    "    else:                     a, b, c =   m, -one, y-m*x\n",
    "    return stackify((a,b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.598096Z",
     "start_time": "2020-07-19T20:48:47.591347Z"
    }
   },
   "outputs": [],
   "source": [
    "p = torch.Tensor([1.5, 2.5])\n",
    "m = torch.Tensor([0.5])[0]\n",
    "assert_allclose_f_ttn(pm2l, (p, m), torch.Tensor([ 0.5000, -1.0000,  1.7500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.602560Z",
     "start_time": "2020-07-19T20:48:47.599159Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def ps2l(p1, p2):\n",
    "    zero = p1.new_tensor(0)\n",
    "\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    if not torch.isclose(x2-x1, zero): m = (y2-y1)/(x2-x1)\n",
    "    else:                              m = p1.new_tensor(math.inf)\n",
    "    return pm2l(p1, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.609222Z",
     "start_time": "2020-07-19T20:48:47.603559Z"
    }
   },
   "outputs": [],
   "source": [
    "p1 = torch.Tensor([1.5, 2.5])\n",
    "p2 = torch.Tensor([2.5, 3.5])\n",
    "assert_allclose_f_ttn(ps2l, (p1, p2), torch.Tensor([ 1.0000,  -1.0000, 1.000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.620722Z",
     "start_time": "2020-07-19T20:48:47.610207Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def pld(p, l):\n",
    "    x, y = p\n",
    "    a, b, c = l\n",
    "    return torch.abs(a*x + b*y + c)/torch.sqrt(a**2 + b**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.633083Z",
     "start_time": "2020-07-19T20:48:47.621751Z"
    }
   },
   "outputs": [],
   "source": [
    "p = torch.Tensor([0.5, 1.5])\n",
    "l = torch.Tensor([1.0000,  0.0000, -1.5000])\n",
    "assert_allclose_f_ttn(pld, (p, l), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.638174Z",
     "start_time": "2020-07-19T20:48:47.634124Z"
    }
   },
   "outputs": [],
   "source": [
    "@numpyify\n",
    "def l_l_intersect(l1, l2):\n",
    "    a1, b1, c1 = l1\n",
    "    a2, b2, c2 = l2\n",
    "    return stackify(((-c1*b2 + b1*c2)/(a1*b2 - b1*a2), (-a1*c2 + c1*a2)/(a1*b2 - b1*a2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.645922Z",
     "start_time": "2020-07-19T20:48:47.639128Z"
    }
   },
   "outputs": [],
   "source": [
    "l1 = torch.Tensor([.1, .2, .3])\n",
    "l2 = torch.Tensor([.4, .2, .2])\n",
    "assert_allclose_f_ttn(l_l_intersect, (l1, l2), torch.Tensor([ 0.3333, -1.6667]), atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bb_ls` gets the lines of an input bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.651856Z",
     "start_time": "2020-07-19T20:48:47.647102Z"
    }
   },
   "outputs": [],
   "source": [
    "@numpyify\n",
    "def bb_ls(bb, dtype):\n",
    "    return stackify((ps2l(torch.tensor([bb[0,0], bb[0,1]], dtype=dtype), \n",
    "                          torch.tensor([bb[0,0], bb[1,1]], dtype=dtype)),\n",
    "                     ps2l(torch.tensor([bb[0,0], bb[0,1]], dtype=dtype), \n",
    "                          torch.tensor([bb[1,0], bb[0,1]], dtype=dtype)),\n",
    "                     ps2l(torch.tensor([bb[0,0], bb[1,1]], dtype=dtype), \n",
    "                          torch.tensor([bb[1,0], bb[1,1]], dtype=dtype)),\n",
    "                     ps2l(torch.tensor([bb[1,0], bb[0,1]], dtype=dtype), \n",
    "                          torch.tensor([bb[1,0], bb[1,1]], dtype=dtype))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.659457Z",
     "start_time": "2020-07-19T20:48:47.652896Z"
    }
   },
   "outputs": [],
   "source": [
    "bb = torch.LongTensor([[1, 2],\n",
    "                       [5, 4]])\n",
    "assert_allclose_f_ttn(bb_ls, (bb, torch.float), torch.Tensor([[ 1.,  0., -1.],\n",
    "                                                              [ 0., -1.,  2.],\n",
    "                                                              [ 0., -1.,  4.],\n",
    "                                                              [ 1.,  0., -5.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.669858Z",
     "start_time": "2020-07-19T20:48:47.660925Z"
    }
   },
   "outputs": [],
   "source": [
    "@numpyify\n",
    "def bb_l_intersect(bb, l):\n",
    "    ls_bb = bb_ls(bb, l.dtype)\n",
    "    ps = []\n",
    "    for l_bb in ls_bb:\n",
    "        p = l_l_intersect(l_bb, l)\n",
    "        if (torch.isclose(p[0], bb[0,0]) or p[0] > bb[0,0]) and \\\n",
    "           (torch.isclose(p[0], bb[1,0]) or p[0] < bb[1,0]) and \\\n",
    "           (torch.isclose(p[1], bb[0,1]) or p[1] > bb[0,1]) and \\\n",
    "           (torch.isclose(p[1], bb[1,1]) or p[1] < bb[1,1]):\n",
    "            ps.append(p)\n",
    "    ps = tuple(ps)\n",
    "    # TODO: handle edge cases (i.e. if line intersects corner or is colinear with edge)\n",
    "    return stackify(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.682116Z",
     "start_time": "2020-07-19T20:48:47.671093Z"
    }
   },
   "outputs": [],
   "source": [
    "bb = torch.Tensor([[-100,-100],[200,200]])\n",
    "l = torch.Tensor([.1,.2,.3])\n",
    "assert_allclose_f_ttn(bb_l_intersect, (bb, l), torch.Tensor([[-100.0000,   48.5000],\n",
    "                                                             [ 197.0000, -100.0000]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ellipse stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample_2pi` prevents accidentally resampling 2pi twice by linspacing with an additional sample and then removing the last sample\n",
    "\n",
    "NOTE: for numpy version to work, you must pass in `np.array(num_samples)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.686902Z",
     "start_time": "2020-07-19T20:48:47.683662Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def sample_2pi(num_samples): return torch.linspace(0, 2*math.pi, int(num_samples)+1)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.693069Z",
     "start_time": "2020-07-19T20:48:47.688120Z"
    }
   },
   "outputs": [],
   "source": [
    "assert_allclose_f_ttn(sample_2pi, torch.Tensor([3]), torch.Tensor([0.0000, 2.0944, 4.1888]), atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.699643Z",
     "start_time": "2020-07-19T20:48:47.694523Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def sample_ellipse(e, num_samples):\n",
    "    h, k, a, b, alpha = e\n",
    "    thetas = sample_2pi(num_samples)\n",
    "    return stackify((a*torch.cos(alpha)*torch.cos(thetas) - b*torch.sin(alpha)*torch.sin(thetas) + h,\n",
    "                     a*torch.sin(alpha)*torch.cos(thetas) + b*torch.cos(alpha)*torch.sin(thetas) + k), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.706760Z",
     "start_time": "2020-07-19T20:48:47.700998Z"
    }
   },
   "outputs": [],
   "source": [
    "e = torch.Tensor([1, 2, 3, 4, math.pi/4])\n",
    "assert_allclose_f_ttn(sample_ellipse, (e, 3), torch.Tensor([[ 3.1213,  4.1213],\n",
    "                                                            [-2.5101,  3.3888],\n",
    "                                                            [ 2.3888, -1.5101]]), atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.716138Z",
     "start_time": "2020-07-19T20:48:47.708109Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def ellipse2conic(e):\n",
    "    h, k, a, b, alpha = e\n",
    "    A = a**2*torch.sin(alpha)**2 + b**2*torch.cos(alpha)**2\n",
    "    B = 2*(b**2 - a**2)*torch.sin(alpha)*torch.cos(alpha)\n",
    "    C = a**2*torch.cos(alpha)**2 + b**2*torch.sin(alpha)**2\n",
    "    D = -2*A*h - B*k\n",
    "    E = -B*h - 2*C*k\n",
    "    F = A*h**2 + B*h*k + C*k**2 - a**2*b**2\n",
    "    return stackify(((  A, B/2, D/2),\n",
    "                     (B/2,   C, E/2),\n",
    "                     (D/2, E/2,   F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.723472Z",
     "start_time": "2020-07-19T20:48:47.717573Z"
    }
   },
   "outputs": [],
   "source": [
    "e = torch.Tensor([1, 2, 3, 4, math.pi/4])\n",
    "assert_allclose_f_ttn(ellipse2conic, e, torch.Tensor([[ 12.5000,   3.5000, -19.5000],\n",
    "                                                      [  3.5000,  12.5000, -28.5000],\n",
    "                                                      [-19.5000, -28.5000, -67.5000]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.736601Z",
     "start_time": "2020-07-19T20:48:47.724457Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def conic2ellipse(Aq):\n",
    "    zero, pi = Aq.new_tensor(0), Aq.new_tensor(math.pi)\n",
    "    \n",
    "    A = Aq[0, 0]\n",
    "    B = 2*Aq[0, 1]\n",
    "    C = Aq[1, 1]\n",
    "    D = 2*Aq[0, 2]\n",
    "    E = 2*Aq[1, 2]\n",
    "    F = Aq[2, 2]\n",
    "\n",
    "    # Return nans if input conic is not ellipse\n",
    "    if torch.any(~torch.isfinite(Aq)) or torch.isclose(B**2-4*A*C, zero) or B**2-4*A*C > 0:\n",
    "        return Aq.new_full((5,), math.nan)\n",
    "\n",
    "    # Equations below are from https://math.stackexchange.com/a/820896/39581\n",
    "\n",
    "    # \"coefficient of normalizing factor\"\n",
    "    q = 64*(F*(4*A*C-B**2)-A*E**2+B*D*E-C*D**2)/(4*A*C-B**2)**2\n",
    "\n",
    "    # distance between center and focal point\n",
    "    s = 1/4*torch.sqrt(torch.abs(q)*torch.sqrt(B**2+(A-C)**2))\n",
    "\n",
    "    # ellipse parameters\n",
    "    h = (B*E-2*C*D)/(4*A*C-B**2)\n",
    "    k = (B*D-2*A*E)/(4*A*C-B**2)\n",
    "    a = 1/8*torch.sqrt(2*torch.abs(q)*torch.sqrt(B**2+(A-C)**2)-2*q*(A+C))\n",
    "    b = torch.sqrt(a**2-s**2)\n",
    "    # Get alpha; note that range of alpha is [0, pi)\n",
    "    if torch.isclose(q*A-q*C, zero) and torch.isclose(q*B, zero): alpha = zero # Circle\n",
    "    elif torch.isclose(q*A-q*C, zero) and q*B > 0:                alpha = 1/4*pi\n",
    "    elif torch.isclose(q*A-q*C, zero) and q*B < 0:                alpha = 3/4*pi\n",
    "    elif q*A-q*C > 0 and (torch.isclose(q*B, zero) or q*B > 0):   alpha = 1/2*torch.atan(B/(A-C))\n",
    "    elif q*A-q*C > 0 and q*B < 0:                                 alpha = 1/2*torch.atan(B/(A-C)) + pi\n",
    "    elif q*A-q*C < 0:                                             alpha = 1/2*torch.atan(B/(A-C)) + 1/2*pi\n",
    "    else: raise RuntimeError('\"Impossible\" condition reached; please debug')\n",
    "\n",
    "    return stackify((h, k, a, b, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.748216Z",
     "start_time": "2020-07-19T20:48:47.737781Z"
    }
   },
   "outputs": [],
   "source": [
    "Aq = torch.Tensor([[  9.56324965,  -1.90407389,  -5.75510187],\n",
    "                   [ -1.90407389,  15.43675035, -28.96942682],\n",
    "                   [ -5.75510187, -28.96942682, -80.3060445 ]])\n",
    "assert_allclose_f_ttn(conic2ellipse, Aq, torch.Tensor([1.0000, 2.0000, 4.0000, 3.0000, 0.2876]), atol=1e-4)\n",
    "assert_allclose(ellipse2conic(conic2ellipse(Aq)), Aq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.752042Z",
     "start_time": "2020-07-19T20:48:47.749789Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def rgb2gray(arr): # From Pillow documentation\n",
    "    return arr[:,:,0]*(299/1000) + arr[:,:,1]*(587/1000) + arr[:,:,2]*(114/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.760644Z",
     "start_time": "2020-07-19T20:48:47.753016Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = torch.Tensor([[[.1,.2,.3],[.2,.2,.2]]])\n",
    "assert_allclose_f_ttn(rgb2gray, arr, torch.Tensor([[0.1815, 0.2000]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.766620Z",
     "start_time": "2020-07-19T20:48:47.761977Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def imresize(arr, sz, mode='bilinear', align_corners=True):\n",
    "    if not isinstance(sz, tuple): sz = tuple((shape(arr)//(shape(arr)/sz).min()).long())\n",
    "    return torch.nn.functional.interpolate(arr[None, None, :, :], \n",
    "                                           size=sz, \n",
    "                                           mode=mode, \n",
    "                                           align_corners=align_corners).squeeze(0).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.773131Z",
     "start_time": "2020-07-19T20:48:47.767582Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = torch.Tensor([[1,1,1,1],\n",
    "                    [2,2,2,2]])\n",
    "assert_allclose_f_ttn(imresize, (arr, 3), torch.Tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
    "                                                        [1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000],\n",
    "                                                        [2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`conv2d` is actually cross correlation, but you can transpose and do the same operation. This is mainly just a helper function to do 2d convolutions easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.777998Z",
     "start_time": "2020-07-19T20:48:47.774072Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def conv2d(arr, kernel, **kwargs):\n",
    "    return torch.nn.functional.conv2d(arr[None,None], kernel[None, None], **kwargs).squeeze(0).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.784736Z",
     "start_time": "2020-07-19T20:48:47.779180Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = torch.Tensor([[1,2,3],\n",
    "                    [3,2,1],\n",
    "                    [1,1,1]])\n",
    "kernel = torch.Tensor([[-0.25, 0.25],\n",
    "                       [-0.25, 0.25]])\n",
    "assert_allclose_f_ttn(conv2d, (arr, kernel), torch.Tensor([[ 0.0000,  0.0000],\n",
    "                                                           [-0.2500, -0.2500]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pad` is just a helper function to do 2d convolutions easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.789563Z",
     "start_time": "2020-07-19T20:48:47.785675Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def pad(arr, pad, mode):\n",
    "    return torch.nn.functional.pad(arr[None,None], pad, mode=mode).squeeze(0).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.795745Z",
     "start_time": "2020-07-19T20:48:47.790474Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = torch.Tensor([[1,2,3],\n",
    "                    [3,2,1],\n",
    "                    [1,1,1]])\n",
    "assert_allclose_f_ttn(pad, (arr, (1,1,1,1), 'replicate'), torch.Tensor([[1,1,2,3,3],\n",
    "                                                                        [1,1,2,3,3],\n",
    "                                                                        [3,3,2,1,1],\n",
    "                                                                        [1,1,1,1,1],\n",
    "                                                                        [1,1,1,1,1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T19:14:18.162748Z",
     "start_time": "2020-07-12T19:14:18.158796Z"
    }
   },
   "source": [
    "`grad_array` by default uses replication to help with gradients along the edges. The default padding in `nn.functional.conv2d` is zero padding, which results in bad gradients along the edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.803419Z",
     "start_time": "2020-07-19T20:48:47.797169Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def grad_array(arr):\n",
    "    kernel_sobel = arr.new_tensor([[-0.1250, 0, 0.1250],\n",
    "                                   [-0.2500, 0, 0.2500],\n",
    "                                   [-0.1250, 0, 0.1250]])\n",
    "    arr = pad(arr, pad=(1,1,1,1), mode='replicate')\n",
    "    return tuple(conv2d(arr, kernel) for kernel in (kernel_sobel, kernel_sobel.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.812104Z",
     "start_time": "2020-07-19T20:48:47.804526Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = torch.Tensor([[1,2,3],\n",
    "                    [3,2,1],\n",
    "                    [1,1,1]])\n",
    "assert_allclose_f_ttn(grad_array, arr, (torch.Tensor([[ 0.2500,  0.5000,  0.2500],\n",
    "                                                      [-0.1250, -0.2500, -0.1250],\n",
    "                                                      [-0.1250, -0.2500, -0.1250]]), \n",
    "                                        torch.Tensor([[ 0.7500,  0.0000, -0.7500],\n",
    "                                                      [-0.1250, -0.5000, -0.8750],\n",
    "                                                      [-0.8750, -0.5000, -0.1250]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wlstsq` is weighted least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.816915Z",
     "start_time": "2020-07-19T20:48:47.813300Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@numpyify\n",
    "def wlstsq(A, b, W=None):\n",
    "    single = len(b.shape) == 1\n",
    "    if single: b = b[:, None]\n",
    "    if W is not None: # Weight matrix is a diagonal matrix with sqrt of the input weights\n",
    "        W = torch.sqrt(W.reshape(-1,1))\n",
    "        A, b = A*W, b*W\n",
    "    x = torch.lstsq(b, A).solution[:A.shape[1],:] # first n rows contains solution\n",
    "    if single: x = x.squeeze(1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.823108Z",
     "start_time": "2020-07-19T20:48:47.818091Z"
    }
   },
   "outputs": [],
   "source": [
    "A = torch.Tensor([[1, 2, 3],\n",
    "                  [2, 3, 4],\n",
    "                  [4, 2, 5],\n",
    "                  [3, 3, 2],\n",
    "                  [1, 6, 7]])\n",
    "b = torch.Tensor([[1, 2],\n",
    "                  [1, 2],\n",
    "                  [1, 2],\n",
    "                  [2, 3],\n",
    "                  [7, 3]])\n",
    "W = torch.Tensor([1, 2, 3, 4, 5])\n",
    "assert_allclose_f_ttn(wlstsq, (A, b, W), torch.Tensor([[-0.5300,  0.4480],\n",
    "                                                       [ 1.0744,  0.6981],\n",
    "                                                       [ 0.1175, -0.2283]]), atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.829933Z",
     "start_time": "2020-07-19T20:48:47.823987Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def get_colors(n): return sns.color_palette(None, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are kind of hacky, but I like being able to rerun a notebook and have it auto save/build/convert at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.836184Z",
     "start_time": "2020-07-19T20:48:47.831101Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def get_notebook_file():\n",
    "    id_kernel = re.search('kernel-(.*).json', ipykernel.connect.get_connection_file()).group(1)\n",
    "    for server in list_running_servers():\n",
    "        response = requests.get(requests.compat.urljoin(server['url'], 'api/sessions'),\n",
    "                                params={'token': server.get('token', '')})\n",
    "        for r in json.loads(response.text):\n",
    "            if 'kernel' in r and r['kernel']['id'] == id_kernel:\n",
    "                return Path(r['notebook']['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.854378Z",
     "start_time": "2020-07-19T20:48:47.837242Z"
    }
   },
   "outputs": [],
   "source": [
    "assert_allclose(get_notebook_file().as_posix(), 'utils.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.857935Z",
     "start_time": "2020-07-19T20:48:47.855479Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def save_notebook():\n",
    "    file_notebook = get_notebook_file()\n",
    "    _get_md5 = lambda : hashlib.md5(file_notebook.read_bytes()).hexdigest() \n",
    "    md5_start = _get_md5()\n",
    "    display(Javascript('IPython.notebook.save_checkpoint();')) # Asynchronous\n",
    "    while md5_start == _get_md5(): time.sleep(1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.863106Z",
     "start_time": "2020-07-19T20:48:47.858953Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def build_notebook(save=True):\n",
    "    if save: save_notebook()\n",
    "    nbdev.export.notebook2script(fname=get_notebook_file().as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:47.869165Z",
     "start_time": "2020-07-19T20:48:47.864053Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def convert_notebook(save=True, t='markdown'):\n",
    "    if save: save_notebook()\n",
    "    os.system(f'jupyter nbconvert --to {t} {get_notebook_file().as_posix()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:36:21.604772Z",
     "start_time": "2020-05-03T20:36:21.600609Z"
    }
   },
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T20:48:48.129735Z",
     "start_time": "2020-07-19T20:48:47.870250Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted utils.ipynb.\n"
     ]
    }
   ],
   "source": [
    "build_notebook()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
