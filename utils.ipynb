{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:38:57.712622Z",
     "start_time": "2020-06-29T02:38:57.709958Z"
    }
   },
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains general utilities used in different modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:38:58.053336Z",
     "start_time": "2020-06-29T02:38:57.714963Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:38:58.056405Z",
     "start_time": "2020-06-29T02:38:58.054561Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T12:57:53.520901Z",
     "start_time": "2020-05-18T12:57:53.517436Z"
    }
   },
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason I can't find a built-in that will reverse and return a list without doing some iterable thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:38:58.065048Z",
     "start_time": "2020-06-29T02:38:58.057482Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def reverse(l): return l[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General numpy/torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch2np` converts a torch tensor to numpy array since its easy to forget when you need to call `detach` and `cpu` and the order required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:38:58.071263Z",
     "start_time": "2020-06-29T02:38:58.066582Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def torch2np(A):\n",
    "    if not isinstance(A, tuple): # Recursion exit condition\n",
    "        if isinstance(A, torch.Tensor): return A.detach().cpu().numpy()\n",
    "        else:                           return A\n",
    "    return tuple(map(torch2np, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`assert_allclose` checks if two things, `A` and `B`, are close to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:38:58.077170Z",
     "start_time": "2020-06-29T02:38:58.072363Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def _assert_allclose(A, B, **kwargs):\n",
    "    if not isinstance(A, tuple): # Recursion exit condition\n",
    "        try:    assert(np.allclose(A, B, **kwargs))\n",
    "        except: assert(np.all(A == B))\n",
    "        return\n",
    "    \n",
    "    for a,b in zip(A,B): _assert_allclose(a, b, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:38:58.083550Z",
     "start_time": "2020-06-29T02:38:58.078092Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def assert_allclose(A, B, **kwargs):\n",
    "    A, B = map(torch2np, [A, B]) # Conversion needed if torch tensor is on gpu, otherwise np.allclose fails\n",
    "    _assert_allclose(A, B, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.096484Z",
     "start_time": "2020-06-29T02:38:58.084548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9530, 0.5480, 0.3687],\n",
       "         [0.9981, 0.8400, 0.0459],\n",
       "         [0.4373, 0.8938, 0.3349],\n",
       "         [0.5041, 0.9184, 0.0670]], device='cuda:0'),\n",
       " array([[ 0.35471579,  0.90508074,  0.5217619 ],\n",
       "        [ 1.4196832 ,  0.11504157,  1.32236272],\n",
       "        [-1.2066323 ,  1.02589301,  2.28333353],\n",
       "        [-2.16652503,  0.37212147, -0.20945945]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand((4,3)).cuda(); \n",
    "B = np.random.normal(size=(4,3))\n",
    "A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.101532Z",
     "start_time": "2020-06-29T02:39:00.097769Z"
    }
   },
   "outputs": [],
   "source": [
    "assert_allclose(A, A+1e-5, atol=1e-5)\n",
    "assert_allclose((A, (B, 1., 'test')), (A+1e-5, (B+1e-5, 1.+1e-5, 'test')), atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have multiple functions that should work for torch and numpy, we should have a way to test for both without having to write duplicate tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.118042Z",
     "start_time": "2020-06-29T02:39:00.102747Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def assert_allclose_f(f, x, y, **kwargs):\n",
    "    if not isinstance(x, tuple): x = (x,)\n",
    "    assert_allclose(f(*x), y, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.124341Z",
     "start_time": "2020-06-29T02:39:00.119272Z"
    }
   },
   "outputs": [],
   "source": [
    "# export \n",
    "def assert_allclose_f_ttn(f, x, y, **kwargs): # ttn == \"torch, then numpy\"\n",
    "    assert_allclose_f(f, x, y, **kwargs) # Torch test\n",
    "    x, y = map(torch2np, [x,y])\n",
    "    assert_allclose_f(f, x, y, **kwargs) # Numpy test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General point stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`psify` decorator will allow functions designed for multiple points to work for single point inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.130581Z",
     "start_time": "2020-06-29T02:39:00.125458Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def psify(f):\n",
    "    def _psify(ps, *args, **kwargs):\n",
    "        single = len(ps.shape) == 1\n",
    "        if single: ps = ps[None]\n",
    "        ps = f(ps, *args, **kwargs)\n",
    "        if single: ps = ps[0]\n",
    "        return ps\n",
    "    return _psify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`augment` will add ones to points; useful for affine and homography xforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.136783Z",
     "start_time": "2020-06-29T02:39:00.132364Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@psify\n",
    "def augment(ps):\n",
    "    if isinstance(ps, np.ndarray): \n",
    "        return np.c_[ps, np.ones(len(ps), dtype=ps.dtype)]\n",
    "    else:\n",
    "        return torch.cat([ps, ps.new_ones((len(ps), 1))], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.144619Z",
     "start_time": "2020-06-29T02:39:00.138330Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = torch.tensor([[0.1940, 0.2536],\n",
    "                   [0.2172, 0.1626],\n",
    "                   [0.9834, 0.2700],\n",
    "                   [0.5324, 0.7137]]).cuda()\n",
    "assert_allclose_f_ttn(augment, ps, torch.tensor([[0.1940, 0.2536, 1.0000],\n",
    "                                                 [0.2172, 0.1626, 1.0000],\n",
    "                                                 [0.9834, 0.2700, 1.0000],\n",
    "                                                 [0.5324, 0.7137, 1.0000]]).cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`deaugment` will remove last column; might wanna add check to make sure column contains ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.148305Z",
     "start_time": "2020-06-29T02:39:00.145622Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@psify\n",
    "def deaugment(ps): return ps[:, 0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.154375Z",
     "start_time": "2020-06-29T02:39:00.149891Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = torch.tensor([[0.1940, 0.2536, 1.0000],\n",
    "                   [0.2172, 0.1626, 1.0000],\n",
    "                   [0.9834, 0.2700, 1.0000],\n",
    "                   [0.5324, 0.7137, 1.0000]]).cuda()\n",
    "assert_allclose_f_ttn(deaugment, ps, torch.tensor([[0.1940, 0.2536],\n",
    "                                                   [0.2172, 0.1626],\n",
    "                                                   [0.9834, 0.2700],\n",
    "                                                   [0.5324, 0.7137]]).cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`normalize` will divide by last column and remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.158531Z",
     "start_time": "2020-06-29T02:39:00.155398Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@psify\n",
    "def normalize(ps): return deaugment(ps/ps[:, [-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T02:00:08.716743Z",
     "start_time": "2020-05-26T02:00:08.710841Z"
    }
   },
   "source": [
    "`unitize` will make norm of each point 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.164444Z",
     "start_time": "2020-06-29T02:39:00.159439Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@psify\n",
    "def unitize(ps): return ps/np.linalg.norm(ps, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pmm` is point matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.172196Z",
     "start_time": "2020-06-29T02:39:00.165392Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@psify\n",
    "def pmm(ps, A, aug=False):\n",
    "    if aug: ps = augment(ps)\n",
    "    ps = (A@ps.T).T\n",
    "    if aug: ps = normalize(ps) # works for both affine and homography transforms\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.179431Z",
     "start_time": "2020-06-29T02:39:00.173367Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = torch.tensor([[0.1940, 0.2536],\n",
    "                   [0.2172, 0.1626],\n",
    "                   [0.9834, 0.2700],\n",
    "                   [0.5324, 0.7137]]).cuda()\n",
    "A = torch.tensor([[0.9571, 0.5551],\n",
    "                  [0.8914, 0.2626]]).cuda()\n",
    "assert_allclose_f_ttn(pmm, (ps,A), torch.tensor([[0.3265, 0.2395],\n",
    "                                                 [0.2981, 0.2363],\n",
    "                                                 [1.0911, 0.9475],\n",
    "                                                 [0.9057, 0.6620]]).cuda(), atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding box stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T00:03:08.202947Z",
     "start_time": "2020-05-26T00:03:08.198828Z"
    }
   },
   "source": [
    "`ps_bb` is points bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.185930Z",
     "start_time": "2020-06-29T02:39:00.180510Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def ps_bb(ps): return np.stack([np.min(ps, axis=0), np.max(ps, axis=0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`array_bb` is array bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.191800Z",
     "start_time": "2020-06-29T02:39:00.187030Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def array_bb(arr): return np.array([[0,0], [arr.shape[1]-1, arr.shape[0]-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bb_sz` returns the size of a bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.198026Z",
     "start_time": "2020-06-29T02:39:00.192768Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def bb_sz(bb):\n",
    "    assert_allclose(bb.dtype, np.int)\n",
    "    return np.array([bb[1,1]-bb[0,1]+1, bb[1,0]-bb[0,0]+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bb_grid` is bounding box grid; i,j is swapped to x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.204242Z",
     "start_time": "2020-06-29T02:39:00.199146Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def bb_grid(bb):\n",
    "    assert_allclose(bb.dtype, np.int)\n",
    "    return reverse(np.mgrid[bb[0,1]:bb[1,1]+1, bb[0,0]:bb[1,0]+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bb_array` applies bounding box to array and returns the sub array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.210532Z",
     "start_time": "2020-06-29T02:39:00.205216Z"
    }
   },
   "outputs": [],
   "source": [
    "# export \n",
    "def bb_array(arr, bb): \n",
    "    assert_allclose(bb.dtype, np.int)\n",
    "    return arr[bb[0,1]:bb[1,1]+1, bb[0,0]:bb[1,0]+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other point stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grid2ps` converts grid to points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.216218Z",
     "start_time": "2020-06-29T02:39:00.211467Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def grid2ps(X, Y, order='C'): return np.c_[X.ravel(order), Y.ravel(order)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`array_ps` is array points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.222065Z",
     "start_time": "2020-06-29T02:39:00.217452Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def array_ps(arr): return grid2ps(*bb_grid(array_bb(arr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`condition_mat` is typically used to \"condition\" points to improve conditioning; its inverse is usually applied afterwards. It sets the mean of the points to zero and the average distance to `sqrt(2)`. I use the term \"condition\" here so I don't get confused with \"normalization\" which is used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.228269Z",
     "start_time": "2020-06-29T02:39:00.222954Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def condition_mat(ps):\n",
    "    xs, ys = ps[:, 0], ps[:, 1]\n",
    "    mean_x, mean_y = xs.mean(), ys.mean()\n",
    "    s_m = np.sqrt(2)*len(ps)/(np.sqrt((xs-mean_x)**2+(ys-mean_y)**2)).sum()\n",
    "    return np.array([[s_m,   0, -mean_x*s_m],\n",
    "                     [  0, s_m, -mean_y*s_m],\n",
    "                     [  0,   0,           1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.234537Z",
     "start_time": "2020-06-29T02:39:00.229250Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def condition(ps):\n",
    "    T = condition_mat(ps)\n",
    "    return pmm(ps, T, aug=True), T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.241001Z",
     "start_time": "2020-06-29T02:39:00.235481Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = array_ps(np.zeros((3,2)))\n",
    "assert_allclose(ps, np.array([[0, 0],\n",
    "                              [1, 0],\n",
    "                              [0, 1],\n",
    "                              [1, 1],\n",
    "                              [0, 2],\n",
    "                              [1, 2]]))\n",
    "assert_allclose(condition_mat(ps), np.array([[ 1.55063424,  0.        , -0.77531712],\n",
    "                                             [ 0.        ,  1.55063424, -1.55063424],\n",
    "                                             [ 0.        ,  0.        ,  1.        ]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`homography` estimates a homography between two sets of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.261481Z",
     "start_time": "2020-06-29T02:39:00.242173Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def homography(ps1, ps2):    \n",
    "    # Condition and augment points\n",
    "    (ps1_cond, T1), (ps2_cond, T2) = map(condition, [ps1, ps2])\n",
    "    ps1_cond, ps2_cond = map(augment, [ps1_cond, ps2_cond])\n",
    "    \n",
    "    # Form homogeneous system\n",
    "    L = np.r_[np.c_[ps1_cond, np.zeros_like(ps1_cond), -ps2_cond[:, 0:1]*ps1_cond],\n",
    "              np.c_[np.zeros_like(ps1_cond), ps1_cond, -ps2_cond[:, 1:2]*ps1_cond]]\n",
    "    \n",
    "    # Solution is the last row of V\n",
    "    _,_,V = np.linalg.svd(L)\n",
    "    H12_cond = V[-1, :].reshape(3,3)\n",
    "    \n",
    "    # Undo conditioning\n",
    "    H12 = np.linalg.inv(T2)@H12_cond@T1\n",
    "    H12 /= H12[2,2] # Sets H12[2,2] to 1\n",
    "    return H12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`approx_R` gives the nearest rotational approximation to the input matrix (I believe frobenium norm). Note that for a proper rotation determinant must be +1, which is checked after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.270159Z",
     "start_time": "2020-06-29T02:39:00.262693Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def approx_R(R):\n",
    "    [U,_,V] = np.linalg.svd(R)\n",
    "    R = U@V\n",
    "    if not np.isclose(np.linalg.det(R), 1):\n",
    "        R = np.full((3,3), np.nan)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.275949Z",
     "start_time": "2020-06-29T02:39:00.271349Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def Rt2M(R, t):\n",
    "    M = torch.cat([R, t[:,None]], dim=1)\n",
    "    M = torch.cat([M, M.new_tensor([[0,0,0,1]])])\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.282096Z",
     "start_time": "2020-06-29T02:39:00.277009Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def M2Rt(M): return M[0:3,0:3], M[0:3,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.288359Z",
     "start_time": "2020-06-29T02:39:00.283488Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def invert_rigid(M):\n",
    "    R, t = M2Rt(M)\n",
    "    return Rt2M(R.T, -R.T@t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.294497Z",
     "start_time": "2020-06-29T02:39:00.289724Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def mult_rigid(M1, M2):\n",
    "    R1, t1 = M2Rt(M1)\n",
    "    R2, t2 = M2Rt(M2)\n",
    "    return Rt2M(R1@R2, R1@t2+t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ellipse stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample_2pi` prevents accidentally resampling 2pi twice by linspacing with an additional sample and then removing the last sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.300025Z",
     "start_time": "2020-06-29T02:39:00.297860Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def sample_2pi(num_samples): return np.linspace(0, 2*np.pi, num_samples+1)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.305663Z",
     "start_time": "2020-06-29T02:39:00.301814Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def sample_ellipse(h, k, a, b, alpha, num_samples):\n",
    "    sin, cos = np.sin, np.cos    \n",
    "    \n",
    "    thetas = sample_2pi(num_samples)\n",
    "    return np.c_[a*cos(alpha)*cos(thetas) - b*sin(alpha)*sin(thetas) + h,\n",
    "                 a*sin(alpha)*cos(thetas) + b*cos(alpha)*sin(thetas) + k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.314138Z",
     "start_time": "2020-06-29T02:39:00.306509Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def ellipse2conic(h, k, a, b, alpha):\n",
    "    sin, cos = np.sin, np.cos\n",
    "    \n",
    "    A = a**2*sin(alpha)**2 + b**2*cos(alpha)**2\n",
    "    B = 2*(b**2 - a**2)*sin(alpha)*cos(alpha)\n",
    "    C = a**2*cos(alpha)**2 + b**2*sin(alpha)**2\n",
    "    D = -2*A*h - B*k\n",
    "    E = -B*h - 2*C*k\n",
    "    F = A*h**2 + B*h*k + C*k**2 - a**2*b**2\n",
    "\n",
    "    return np.array([[  A, B/2, D/2],\n",
    "                     [B/2,   C, E/2],\n",
    "                     [D/2, E/2,   F]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.324077Z",
     "start_time": "2020-06-29T02:39:00.315136Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def conic2ellipse(Aq):\n",
    "    sqrt, abs, arctan, pi = np.sqrt, np.abs, np.arctan, np.pi\n",
    "    \n",
    "    A = Aq[0, 0]\n",
    "    B = 2*Aq[0, 1]\n",
    "    C = Aq[1, 1]\n",
    "    D = 2*Aq[0, 2]\n",
    "    E = 2*Aq[1, 2]\n",
    "    F = Aq[2, 2]\n",
    "\n",
    "    # Return nans if input conic is not ellipse\n",
    "    if np.any(~np.isfinite(Aq.ravel())) or np.isclose(B**2-4*A*C, 0) or B**2-4*A*C > 0:\n",
    "        return np.full(5, np.nan)\n",
    "\n",
    "    # Equations below are from https://math.stackexchange.com/a/820896/39581\n",
    "\n",
    "    # \"coefficient of normalizing factor\"\n",
    "    q = 64*(F*(4*A*C-B**2)-A*E**2+B*D*E-C*D**2)/(4*A*C-B**2)**2\n",
    "\n",
    "    # distance between center and focal point\n",
    "    s = 1/4*sqrt(abs(q)*sqrt(B**2+(A-C)**2))\n",
    "\n",
    "    # ellipse parameters\n",
    "    h = (B*E-2*C*D)/(4*A*C-B**2)\n",
    "    k = (B*D-2*A*E)/(4*A*C-B**2)\n",
    "    a = 1/8*sqrt(2*abs(q)*sqrt(B**2+(A-C)**2)-2*q*(A+C))\n",
    "    b = sqrt(a**2-s**2)\n",
    "    # Get alpha; note that range of alpha is [0, pi)\n",
    "    if np.isclose(q*A-q*C, 0) and np.isclose(q*B, 0):     alpha = 0 # Circle\n",
    "    elif np.isclose(q*A-q*C, 0) and q*B > 0:              alpha = 1/4*pi\n",
    "    elif np.isclose(q*A-q*C, 0) and q*B < 0:              alpha = 3/4*pi\n",
    "    elif q*A-q*C > 0 and (np.isclose(q*B, 0) or q*B > 0): alpha = 1/2*arctan(B/(A-C))\n",
    "    elif q*A-q*C > 0 and q*B < 0:                         alpha = 1/2*arctan(B/(A-C)) + pi\n",
    "    elif q*A-q*C < 0:                                     alpha = 1/2*arctan(B/(A-C)) + 1/2*pi\n",
    "    else: raise RuntimeError('\"Impossible\" condition reached; please debug')\n",
    "\n",
    "    return h, k, a, b, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think `conv2d` is actually cross correlation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.332634Z",
     "start_time": "2020-06-29T02:39:00.325042Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def conv2d(arr, kernel, **kwargs):\n",
    "    assert_allclose(arr.dtype, kernel.dtype)\n",
    "    _conv2d = torch.nn.functional.conv2d\n",
    "    arr, kernel = map(torch.tensor, [arr, kernel])\n",
    "    return torch2np(_conv2d(arr[None,None], kernel[None, None], **kwargs)).squeeze(axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.338666Z",
     "start_time": "2020-06-29T02:39:00.333759Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def grad_array(arr):\n",
    "    kernel_sobel = np.array([[-0.1250, 0, 0.1250],\n",
    "                             [-0.2500, 0, 0.2500],\n",
    "                             [-0.1250, 0, 0.1250]], dtype=arr.dtype)\n",
    "    arr = np.pad(arr, 1, mode='edge')\n",
    "    return [conv2d(arr, kernel) for kernel in [kernel_sobel, kernel_sobel.T]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wlstsq` is weighted least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.346940Z",
     "start_time": "2020-06-29T02:39:00.339702Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def wlstsq(A, b, W=None):\n",
    "    # Weights should be a diagonal matrix with sqrt of the input weights\n",
    "    if W is not None:\n",
    "        W = np.sqrt(W.ravel())\n",
    "        A, b = A*W[:,None], b*W\n",
    "    return np.linalg.lstsq(A, b, rcond=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:36:21.604772Z",
     "start_time": "2020-05-03T20:36:21.600609Z"
    }
   },
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.354300Z",
     "start_time": "2020-06-29T02:39:00.347895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:39:00.997132Z",
     "start_time": "2020-06-29T02:39:00.355311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted README.ipynb.\n",
      "Converted calib.ipynb.\n",
      "Converted cb_geom.ipynb.\n",
      "Converted control_refine.ipynb.\n",
      "Converted fiducial_detect.ipynb.\n",
      "Converted image.ipynb.\n",
      "Converted modules.ipynb.\n",
      "Converted plot.ipynb.\n",
      "Converted utils.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
