{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:23.551639Z",
     "start_time": "2020-05-25T02:45:23.549588Z"
    }
   },
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains general utilities used in different modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:23.886668Z",
     "start_time": "2020-05-25T02:45:23.553187Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:23.889592Z",
     "start_time": "2020-05-25T02:45:23.887747Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T12:57:53.520901Z",
     "start_time": "2020-05-18T12:57:53.517436Z"
    }
   },
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason I can't find a built-in that will reverse and return a list without doing some iterable thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:23.897938Z",
     "start_time": "2020-05-25T02:45:23.890456Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def reverse(l): return l[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch2np` converts a torch tensor to numpy array since its easy to forget when you need to call `detach` and `cpu` and the order required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:23.903682Z",
     "start_time": "2020-05-25T02:45:23.899145Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def torch2np(A):\n",
    "    if not isinstance(A, tuple): # Recursion exit condition\n",
    "        if isinstance(A, torch.Tensor): return A.detach().cpu().numpy()\n",
    "        else:                           return A\n",
    "    return tuple(map(torch2np, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`assert_allclose` checks if two things, `A` and `B`, are close to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:23.909566Z",
     "start_time": "2020-05-25T02:45:23.904771Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def _assert_allclose(A, B, **kwargs): # Inputs should be numpy arrays\n",
    "    assert(type(A) == type(B))\n",
    "    \n",
    "    if not isinstance(A, tuple): # Recursion exit condition\n",
    "        try:    assert(np.allclose(A, B, **kwargs))\n",
    "        except: assert(np.all(A == B))\n",
    "        return\n",
    "    \n",
    "    for a,b in zip(A,B): _assert_allclose(a, b, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:23.915338Z",
     "start_time": "2020-05-25T02:45:23.910420Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def assert_allclose(A, B, **kwargs):\n",
    "    A, B = map(torch2np, [A, B]) # Convert so np.allclose can be used, which seems more robust\n",
    "    _assert_allclose(A, B, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.852480Z",
     "start_time": "2020-05-25T02:45:23.916263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9554, 0.2218, 0.3948],\n",
       "         [0.1342, 0.0637, 0.4097],\n",
       "         [0.4054, 0.0134, 0.4256],\n",
       "         [0.8681, 0.9768, 0.3564]], device='cuda:0'),\n",
       " array([[ 0.04615469,  1.62008664,  0.44742344],\n",
       "        [-0.41118388, -0.14312051,  0.2989598 ],\n",
       "        [ 1.17475593, -0.64503034, -0.88266093],\n",
       "        [ 1.55329052,  1.32801848,  0.33225744]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand((4,3)).cuda(); \n",
    "B = np.random.normal(size=(4,3))\n",
    "A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.858676Z",
     "start_time": "2020-05-25T02:45:25.853965Z"
    }
   },
   "outputs": [],
   "source": [
    "assert_allclose(A, A+1e-5, atol=1e-5)\n",
    "assert_allclose((A, (B, 1., 'test')), (A+1e-5, (B+1e-5, 1.+1e-5, 'test')), atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have multiple functions that should work for torch and numpy, we should have a way to test for both without having to write duplicate tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.871476Z",
     "start_time": "2020-05-25T02:45:25.860025Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def assert_allclose_f(f, x, y, **kwargs):\n",
    "    if not isinstance(x, tuple): x = (x,)\n",
    "    assert_allclose(f(*x), y, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.877452Z",
     "start_time": "2020-05-25T02:45:25.872929Z"
    }
   },
   "outputs": [],
   "source": [
    "# export \n",
    "def assert_allclose_f_ttn(f, x, y, **kwargs): # ttn == \"torch, then numpy\"\n",
    "    assert_allclose_f(f, x, y, **kwargs) # Torch test\n",
    "    x, y = map(torch2np, [x,y])\n",
    "    assert_allclose_f(f, x, y, **kwargs) # Numpy test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General numpy/torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch2np` converts a torch tensor to numpy array since its easy to forget when you need to call `detach` and `cpu` and the order required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.883415Z",
     "start_time": "2020-05-25T02:45:25.878738Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def torch2np(A):\n",
    "    if not isinstance(A, tuple): # Recursion exit condition\n",
    "        if isinstance(A, torch.Tensor): return A.detach().cpu().numpy()\n",
    "        else:                           return A\n",
    "    return tuple(map(torch2np, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General point stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`augment` will add ones to points; useful overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.891499Z",
     "start_time": "2020-05-25T02:45:25.886690Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def augment(ps):\n",
    "    if isinstance(ps, np.ndarray): \n",
    "        return np.c_[ps, np.ones(len(ps), dtype=ps.dtype)]\n",
    "    else:                          \n",
    "        return torch.cat([ps, ps.new_ones((len(ps), 1))], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.900232Z",
     "start_time": "2020-05-25T02:45:25.892821Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = torch.tensor([[0.1940, 0.2536],\n",
    "                   [0.2172, 0.1626],\n",
    "                   [0.9834, 0.2700],\n",
    "                   [0.5324, 0.7137]]).cuda()\n",
    "assert_allclose_f_ttn(augment, ps, torch.tensor([[0.1940, 0.2536, 1.0000],\n",
    "                                                 [0.2172, 0.1626, 1.0000],\n",
    "                                                 [0.9834, 0.2700, 1.0000],\n",
    "                                                 [0.5324, 0.7137, 1.0000]]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.903855Z",
     "start_time": "2020-05-25T02:45:25.901364Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def deaugment(ps): return ps[:, 0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.914041Z",
     "start_time": "2020-05-25T02:45:25.905344Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = torch.tensor([[0.1940, 0.2536, 1.0000],\n",
    "                   [0.2172, 0.1626, 1.0000],\n",
    "                   [0.9834, 0.2700, 1.0000],\n",
    "                   [0.5324, 0.7137, 1.0000]]).cuda()\n",
    "assert_allclose_f_ttn(deaugment, ps, torch.tensor([[0.1940, 0.2536],\n",
    "                                                   [0.2172, 0.1626],\n",
    "                                                   [0.9834, 0.2700],\n",
    "                                                   [0.5324, 0.7137]]).cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pmm` is point matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.919679Z",
     "start_time": "2020-05-25T02:45:25.914981Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def pmm(A, ps, aug_ps=False): \n",
    "    single = len(ps.shape) == 1\n",
    "    if single: ps = ps[None]\n",
    "    if aug_ps: ps = augment(ps)\n",
    "    ps = (A@ps.T).T\n",
    "    if aug_ps: ps = deaugment(ps)\n",
    "    if single: ps = ps[0]\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.927253Z",
     "start_time": "2020-05-25T02:45:25.920943Z"
    }
   },
   "outputs": [],
   "source": [
    "A = torch.tensor([[0.9571, 0.5551],\n",
    "                  [0.8914, 0.2626]]).cuda()\n",
    "ps = torch.tensor([[0.1940, 0.2536],\n",
    "                   [0.2172, 0.1626],\n",
    "                   [0.9834, 0.2700],\n",
    "                   [0.5324, 0.7137]]).cuda()\n",
    "assert_allclose_f_ttn(pmm, (A,ps), torch.tensor([[0.3265, 0.2395],\n",
    "                                                 [0.2981, 0.2363],\n",
    "                                                 [1.0911, 0.9475],\n",
    "                                                 [0.9057, 0.6620]]).cuda(), atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`normalize` will divide by 3rd dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.933735Z",
     "start_time": "2020-05-25T02:45:25.928630Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def normalize(ps): return ps[:,0:2]/ps[:,2:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`array_bb` is array bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.940360Z",
     "start_time": "2020-05-25T02:45:25.934817Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def array_bb(arr): return np.array([[0,0], [arr.shape[1], arr.shape[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bb_grid` is bounding box grid; i,j is swapped to x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.946516Z",
     "start_time": "2020-05-25T02:45:25.941464Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def bb_grid(bb): return reverse(np.mgrid[bb[0,1]:bb[1,1], bb[0,0]:bb[1,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grid2ps` converts grid to points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.952317Z",
     "start_time": "2020-05-25T02:45:25.947979Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def grid2ps(X, Y, order='C'): return np.c_[X.ravel(order), Y.ravel(order)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`array_ps` is array points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.958373Z",
     "start_time": "2020-05-25T02:45:25.953465Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def array_ps(arr): return grid2ps(*bb_grid(array_bb(arr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bb_array` applies bounding box to array and returns the sub array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.964450Z",
     "start_time": "2020-05-25T02:45:25.959680Z"
    }
   },
   "outputs": [],
   "source": [
    "# export \n",
    "def bb_array(arr, bb): return arr[bb[0,1]:bb[1,1], bb[0,0]:bb[1,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bb_sz` returns the size of the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.973892Z",
     "start_time": "2020-05-25T02:45:25.965670Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def bb_sz(bb): return np.array([bb[1,1]-bb[0,1], bb[1,0]-bb[0,0]], dtype=np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`condition_mat` is typically used to \"condition\" points to improve conditioning; its inverse is usually applied afterwards. It ensures the mean of the points is zero and the average distance is `sqrt(2)`. I use the term \"condition\" here so it doesn't get confused with \"normalization\" which is used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.979631Z",
     "start_time": "2020-05-25T02:45:25.974808Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def condition_mat(ps):\n",
    "    xs, ys = ps[:, 0], ps[:, 1]\n",
    "    mean_x, mean_y = xs.mean(), ys.mean()\n",
    "    s_m = np.sqrt(2)*len(ps)/(np.sqrt((xs-mean_x)**2+(ys-mean_y)**2)).sum()\n",
    "    return np.array([[s_m,   0, -mean_x*s_m],\n",
    "                     [  0, s_m, -mean_y*s_m],\n",
    "                     [  0,   0,           1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.985662Z",
     "start_time": "2020-05-25T02:45:25.980653Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def condition(ps):\n",
    "    T = condition_mat(ps)\n",
    "    return pmm(T, ps, aug_ps=True), T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:25.992161Z",
     "start_time": "2020-05-25T02:45:25.986861Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = array_ps(np.zeros((3,2)))\n",
    "assert_allclose(ps, np.array([[0, 0],\n",
    "                              [1, 0],\n",
    "                              [0, 1],\n",
    "                              [1, 1],\n",
    "                              [0, 2],\n",
    "                              [1, 2]]))\n",
    "assert_allclose(condition_mat(ps), np.array([[ 1.55063424,  0.        , -0.77531712],\n",
    "                                             [ 0.        ,  1.55063424, -1.55063424],\n",
    "                                             [ 0.        ,  0.        ,  1.        ]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ellipse stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample_2pi` prevents accidentally resampling 2pi twice by linspacing with an additional sample and then removing the last sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:26.000694Z",
     "start_time": "2020-05-25T02:45:25.993158Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def sample_2pi(num_samples): return np.linspace(0, 2*np.pi, num_samples+1)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:26.006943Z",
     "start_time": "2020-05-25T02:45:26.001855Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def sample_ellipse(h, k, a, b, alpha, num_samples):\n",
    "    sin, cos = np.sin, np.cos    \n",
    "    \n",
    "    thetas = sample_2pi(num_samples)\n",
    "    return np.c_[a*cos(alpha)*cos(thetas) - b*sin(alpha)*sin(thetas) + h,\n",
    "                 a*sin(alpha)*cos(thetas) + b*cos(alpha)*sin(thetas) + k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:26.013284Z",
     "start_time": "2020-05-25T02:45:26.007932Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def ellipse2conic(h, k, a, b, alpha):\n",
    "    sin, cos = np.sin, np.cos\n",
    "    \n",
    "    A = a**2*sin(alpha)**2 + b**2*cos(alpha)**2\n",
    "    B = 2*(b**2 - a**2)*sin(alpha)*cos(alpha)\n",
    "    C = a**2*cos(alpha)**2 + b**2*sin(alpha)**2\n",
    "    D = -2*A*h - B*k\n",
    "    E = -B*h - 2*C*k\n",
    "    F = A*h**2 + B*h*k + C*k**2 - a**2*b**2\n",
    "\n",
    "    return np.array([[  A, B/2, D/2],\n",
    "                     [B/2,   C, E/2],\n",
    "                     [D/2, E/2,   F]], dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:26.023240Z",
     "start_time": "2020-05-25T02:45:26.014329Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def conic2ellipse(Aq):\n",
    "    sqrt, abs, arctan, pi = np.sqrt, np.abs, np.arctan, np.pi\n",
    "    eps = np.finfo(np.float32).eps # Use single precision for more wiggle room\n",
    "    \n",
    "    A = Aq[0, 0]\n",
    "    B = 2*Aq[0, 1]\n",
    "    C = Aq[1, 1]\n",
    "    D = 2*Aq[0, 2]\n",
    "    E = 2*Aq[1, 2]\n",
    "    F = Aq[2, 2]\n",
    "\n",
    "    # Return nans if input conic is not ellipse\n",
    "    if np.any(~np.isfinite(Aq.ravel())) or np.abs(B**2-4*A*C) < eps or B**2-4*A*C > 0:\n",
    "        return np.full(5, np.nan)\n",
    "\n",
    "    # Equations below are from https://math.stackexchange.com/a/820896/39581\n",
    "\n",
    "    # \"coefficient of normalizing factor\"\n",
    "    q = 64*(F*(4*A*C-B**2)-A*E**2+B*D*E-C*D**2)/(4*A*C-B**2)**2\n",
    "\n",
    "    # distance between center and focal point\n",
    "    s = 1/4*sqrt(abs(q)*sqrt(B**2+(A-C)**2))\n",
    "\n",
    "    # ellipse parameters\n",
    "    h = (B*E-2*C*D)/(4*A*C-B**2)\n",
    "    k = (B*D-2*A*E)/(4*A*C-B**2)\n",
    "    a = 1/8*sqrt(2*abs(q)*sqrt(B**2+(A-C)**2)-2*q*(A+C))\n",
    "    b = sqrt(a**2-s**2)\n",
    "    # Get alpha; note that range of alpha is [0, pi)\n",
    "    if abs(q*A-q*C) < eps and abs(q*B) < eps:         alpha = 0 # Circle\n",
    "    elif abs(q*A-q*C) < eps and q*B > 0:              alpha = 1/4*pi\n",
    "    elif abs(q*A-q*C) < eps and q*B < 0:              alpha = 3/4*pi\n",
    "    elif q*A-q*C > 0 and (abs(q*B) < eps or q*B > 0): alpha = 1/2*arctan(B/(A-C))\n",
    "    elif q*A-q*C > 0 and q*B < 0:                     alpha = 1/2*arctan(B/(A-C)) + pi\n",
    "    elif q*A-q*C < 0:                                 alpha = 1/2*arctan(B/(A-C)) + 1/2*pi\n",
    "    else: raise RuntimeError('\"Impossible\" condition reached; please debug')\n",
    "\n",
    "    return h, k, a, b, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T13:16:42.671125Z",
     "start_time": "2020-05-18T13:16:42.666722Z"
    }
   },
   "source": [
    "Let `grad_array` be a function, as I might want to change how gradients are computed; i,j is swapped to x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:26.031036Z",
     "start_time": "2020-05-25T02:45:26.024168Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def grad_array(arr): return reverse(np.gradient(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wlstsq` is weighted least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:26.037084Z",
     "start_time": "2020-05-25T02:45:26.032082Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def wlstsq(A, b, W=None):\n",
    "    # Weights should be a diagonal matrix with sqrt of the input weights\n",
    "    if W is not None:\n",
    "        W = np.sqrt(W.ravel())\n",
    "        A, b = A*W[:,None], b*W\n",
    "    return np.linalg.lstsq(A, b, rcond=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:36:21.604772Z",
     "start_time": "2020-05-03T20:36:21.600609Z"
    }
   },
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:45:26.701248Z",
     "start_time": "2020-05-25T02:45:26.038088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted cb_geom.ipynb.\n",
      "Converted control_refine.ipynb.\n",
      "Converted coordinate_graph.ipynb.\n",
      "Converted fiducial_detect.ipynb.\n",
      "Converted image.ipynb.\n",
      "Converted modules.ipynb.\n",
      "Converted test.ipynb.\n",
      "Converted utils.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
